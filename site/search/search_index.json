{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Token Sentiment Bot API Documentation","text":"<p>Welcome to the API documentation for the Token Sentiment Telegram Bot - a sophisticated cryptocurrency token analysis system that combines on-chain data, social sentiment, and market fundamentals.</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>The Token Sentiment Bot analyzes cryptocurrency tokens using three data pillars:</p> <ul> <li>\ud83d\udcca Onchain Analysis (60%): Smart money flows via Nansen</li> <li>\ud83d\udc26 Social Sentiment (25%): Twitter sentiment analysis  </li> <li>\ud83d\udcc8 Market Fundamentals (15%): Market cap, volume, and financial ratios</li> </ul>"},{"location":"#api-reference","title":"\ud83d\udcda API Reference","text":""},{"location":"#core-modules","title":"Core Modules","text":"<ul> <li>Sentiment Engine - Main analysis engine with weighting and confidence calculation</li> <li>Data Sources - API wrappers for Twitter, Nansen, and CoinGecko</li> <li>Cache - Hybrid caching system (Redis + in-memory fallback)</li> <li>Validation - Token address validation for multiple networks</li> <li>HTTP Utils - Robust HTTP requests with retry logic</li> <li>Rate Limiter - In-memory rate limiting for user requests</li> </ul>"},{"location":"#bot-implementation","title":"Bot Implementation","text":"<ul> <li>Main Bot - Telegram bot core with webhook handling</li> </ul>"},{"location":"#development","title":"\ud83d\udee0\ufe0f Development","text":"<ul> <li>Testing - Comprehensive test suite and coverage</li> <li>Load Testing - Performance testing with Locust</li> <li>Deployment - Deployment options and configuration</li> </ul>"},{"location":"#project-status","title":"\ud83d\udcca Project Status","text":"<ul> <li>Test Coverage: 77% (150+ tests)</li> <li>Supported Networks: Ethereum, Solana, BSC, Polygon, Arbitrum, Optimism, Avalanche, Fantom</li> <li>Rate Limiting: 2 analyses per minute per user</li> <li>Response Time: &lt;7 seconds median</li> </ul>"},{"location":"#getting-started","title":"\ud83d\udd27 Getting Started","text":"<pre><code>from core.sentiment_engine import SentimentEngine\n\n# Initialize the sentiment engine\nengine = SentimentEngine()\n\n# Analyze a token\nresult = await engine.analyze_token(\"0x1f9840a85d5af5bf1d1762f925bdaddc4201f984\")\n\nprint(f\"Signal: {result.signal}\")\nprint(f\"Confidence: {result.confidence:.1%}\")\nprint(f\"Score: {result.overall_score:.3f}\")\n</code></pre>"},{"location":"#usage-examples","title":"\ud83d\udcd6 Usage Examples","text":"<p>See the individual API documentation pages for detailed examples and usage patterns for each module.</p> <p>Built with \u2764\ufe0f for the crypto community </p>"},{"location":"api/bot_main/","title":"Main Bot","text":"<p>Token Sentiment Telegram Bot</p> <p>Main bot application with webhook handler for processing user requests and returning token sentiment analysis with confidence scores and rationale.</p> <p>Features: - Webhook-based message handling - Token address validation (EVM &amp; Solana) - Integration with SentimentEngine - Rate limiting (2 analyses per minute per user) - Formatted responses with emojis and disclaimers</p>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot","title":"<code>TokenSentimentBot</code>","text":"<p>Token Sentiment Telegram Bot with webhook support.</p> Source code in <code>bot/main.py</code> <pre><code>class TokenSentimentBot:\n    \"\"\"Token Sentiment Telegram Bot with webhook support.\"\"\"\n\n    def __init__(self, token: str, webhook_url: str):\n        \"\"\"Initialize the bot with token and webhook configuration.\"\"\"\n        self.token = token\n        self.webhook_url = webhook_url\n        self.application = None\n        self.sentiment_engine = SentimentEngine()\n\n    async def initialize(self):\n        \"\"\"Initialize the bot application and set up handlers.\"\"\"\n        # Create application\n        self.application = Application.builder().token(self.token).build()\n\n        # Add command handlers\n        self.application.add_handler(CommandHandler(\"start\", self.start_command))\n        self.application.add_handler(CommandHandler(\"help\", self.help_command))\n        self.application.add_handler(CommandHandler(\"stats\", self.stats_command))\n\n        # Add message handler for token addresses\n        self.application.add_handler(\n            MessageHandler(filters.TEXT &amp; ~filters.COMMAND, self.handle_message)\n        )\n\n        # Initialize the application\n        await self.application.initialize()\n\n        logger.info(\"Bot initialized successfully\")\n\n    async def start_webhook(self, webhook_path: str = WEBHOOK_PATH, port: int = WEBHOOK_PORT):\n        \"\"\"Start the webhook server.\"\"\"\n        if not self.application:\n            raise RuntimeError(\"Bot application not initialized\")\n\n        try:\n            # Set webhook\n            await self.application.bot.set_webhook(\n                url=f\"{self.webhook_url}{webhook_path}\",\n                allowed_updates=['message', 'callback_query']\n            )\n\n            # Start webhook server\n            await self.application.run_webhook(\n                listen=\"0.0.0.0\",\n                port=port,\n                url_path=webhook_path,\n                webhook_url=f\"{self.webhook_url}{webhook_path}\"\n            )\n\n            logger.info(f\"Webhook started on {self.webhook_url}{webhook_path}\")\n\n        except Exception as e:\n            logger.error(f\"Failed to start webhook: {e}\")\n            raise\n\n    async def stop(self):\n        \"\"\"Stop the bot and cleanup resources.\"\"\"\n        if self.application:\n            await self.application.shutdown()\n            logger.info(\"Bot stopped\")\n\n    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /start command.\"\"\"\n        if not update.message:\n            return\n\n        welcome_message = (\n            \"\ud83e\udd16 **Token Sentiment Analysis Bot**\\n\\n\"\n            \"I analyze token sentiment using:\\n\"\n            \"\u2022 \ud83d\udcca **Onchain data** (60%): Smart money flows\\n\"\n            \"\u2022 \ud83d\udc26 **Social signals** (25%): Twitter sentiment\\n\"\n            \"\u2022 \ud83d\udcc8 **Fundamentals** (15%): Trading activity\\n\\n\"\n            \"**How to use:**\\n\"\n            \"Just send me a token contract address!\\n\\n\"\n            \"\ud83d\udcf1 Commands:\\n\"\n            \"/help - Show detailed help\\n\"\n            \"/stats - View usage statistics\\n\\n\"\n            \"\u26a0\ufe0f *Not financial advice. DYOR.*\"\n        )\n\n        await update.message.reply_text(\n            welcome_message,\n            parse_mode=ParseMode.MARKDOWN\n        )\n\n    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /help command with detailed usage instructions.\"\"\"\n        if not update.message:\n            return\n\n        help_message = (\n            \"\ud83d\udcd6 **Token Sentiment Bot - Complete Guide**\\n\\n\"\n\n            \"\ud83d\ude80 **Quick Start:**\\n\"\n            \"Just send me a token contract address and I'll analyze it!\\n\\n\"\n\n            \"**\ud83d\udcf1 Available Commands:**\\n\"\n            \"\u2022 `/start` - Welcome message and overview\\n\"\n            \"\u2022 `/help` - Show this detailed help guide\\n\"\n            \"\u2022 `/stats` - View bot statistics and your usage\\n\\n\"\n\n            \"**\ud83c\udf10 Supported Networks:**\\n\"\n            \"\u2022 **Ethereum** - 0x followed by 40 hex characters\\n\"\n            \"  Example: `0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984`\\n\"\n            \"\u2022 **Solana** - Base58 address (32-44 characters)\\n\"\n            \"  Example: `EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v`\\n\\n\"\n\n            \"**\ud83d\udcca What You'll Get:**\\n\"\n            \"\ud83d\udd38 **Sentiment Signal**: \ud83d\udfe2 Bullish / \ud83d\udfe1 Neutral / \ud83d\udd34 Bearish\\n\"\n            \"\ud83d\udd38 **Confidence Score**: 0-100% based on data quality\\n\"\n            \"\ud83d\udd38 **Detailed Rationale**: 3-bullet explanation with metrics\\n\"\n            \"\ud83d\udd38 **Analysis Breakdown**: Specific data points and context\\n\\n\"\n\n            \"**\ud83d\udd0d Data Sources &amp; Weighting:**\\n\"\n            \"\u2022 **\ud83d\udcca Onchain Data (60%)**: Nansen smart money flows\\n\"\n            \"  - Whale wallet movements\\n\"\n            \"  - Smart money trading patterns\\n\"\n            \"  - Volume and flow analysis\\n\\n\"\n            \"\u2022 **\ud83d\udc26 Social Signals (25%)**: Twitter sentiment\\n\"\n            \"  - Real-time tweet analysis\\n\"\n            \"  - Sentiment scoring algorithms\\n\"\n            \"  - Community engagement metrics\\n\\n\"\n            \"\u2022 **\ud83d\udcc8 Fundamentals (15%)**: Market metrics\\n\"\n            \"  - Market capitalization\\n\"\n            \"  - Trading volume ratios\\n\"\n            \"  - Liquidity indicators\\n\\n\"\n\n            \"**\u23f1\ufe0f Usage Limits:**\\n\"\n            \"\u2022 **Rate Limit**: 2 analyses per minute per user\\n\"\n            \"\u2022 **Cache**: Results cached for 5 minutes\\n\"\n            \"\u2022 **Response Time**: Typically 3-7 seconds\\n\\n\"\n\n            \"**\ud83d\udca1 Tips for Best Results:**\\n\"\n            \"\u2022 Use popular tokens for highest data quality\\n\"\n            \"\u2022 Check multiple timeframes for trend confirmation\\n\"\n            \"\u2022 Consider confidence scores when making decisions\\n\"\n            \"\u2022 Always verify addresses before sending\\n\\n\"\n\n            \"**\u2753 Troubleshooting:**\\n\"\n            \"\u2022 **Invalid Address**: Check format and network\\n\"\n            \"\u2022 **Analysis Failed**: Token may not have sufficient data\\n\"\n            \"\u2022 **Rate Limited**: Wait 1 minute between requests\\n\"\n            \"\u2022 **Slow Response**: High network traffic, please wait\\n\\n\"\n\n            \"**\ud83d\udee1\ufe0f Important Disclaimer:**\\n\"\n            \"*This analysis is for informational purposes only and does not constitute financial advice. \"\n            \"The bot uses algorithmic analysis of onchain flows, social sentiment, and market fundamentals. \"\n            \"Always conduct your own research (DYOR) before making any investment decisions.*\\n\\n\"\n\n            \"**\ud83d\udcde Need Help?**\\n\"\n            \"If you encounter issues or have questions, please contact support.\"\n        )\n\n        await update.message.reply_text(\n            help_message,\n            parse_mode=ParseMode.MARKDOWN\n        )\n\n    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle /stats command returning usage metrics.\"\"\"\n        if not update.message or not update.effective_user:\n            return\n\n        user_id = update.effective_user.id\n        current_time = time.time()\n\n        # Calculate uptime\n        uptime_seconds = current_time - bot_stats[\"start_time\"]\n        uptime_hours = uptime_seconds / 3600\n        uptime_days = uptime_hours / 24\n\n        # Format uptime\n        if uptime_days &gt;= 1:\n            uptime_str = f\"{uptime_days:.1f} days\"\n        elif uptime_hours &gt;= 1:\n            uptime_str = f\"{uptime_hours:.1f} hours\"\n        else:\n            uptime_str = f\"{uptime_seconds/60:.1f} minutes\"\n\n        # Get user rate limiting statistics from new rate limiter\n        user_rate_stats = get_user_rate_limit_stats(user_id)\n        global_rate_stats = get_global_rate_limit_stats()\n\n        # Per-user stats\n        user_total_requests = user_rate_stats.get('total_requests', 0)\n        user_recent_requests = user_rate_stats.get('recent_requests', 0)\n        user_remaining = user_rate_stats.get('remaining_requests', 0)\n        user_max = user_rate_stats.get('max_requests', 2)\n        user_window = user_rate_stats.get('window_seconds', 60)\n        user_last_request = user_rate_stats.get('last_request')\n\n        # Global stats\n        global_total_users = global_rate_stats.get('total_users', 0)\n        global_total_requests = global_rate_stats.get('total_requests', 0)\n        global_recent_requests = global_rate_stats.get('recent_requests', 0)\n        global_window = global_rate_stats.get('window_seconds', 60)\n        global_last_request = global_rate_stats.get('last_request')\n\n        # Calculate average confidence\n        avg_confidence = 0\n        if bot_stats[\"average_confidence\"]:\n            avg_confidence = sum(bot_stats[\"average_confidence\"]) / len(bot_stats[\"average_confidence\"])\n\n        # Calculate analyses per hour\n        analyses_per_hour = 0\n        if uptime_hours &gt; 0:\n            analyses_per_hour = bot_stats[\"total_analyses\"] / uptime_hours\n\n        # Calculate cache hit ratio\n        total_cache_requests = bot_stats[\"cache_hits\"] + bot_stats[\"cache_misses\"]\n        cache_hit_ratio = 0\n        if total_cache_requests &gt; 0:\n            cache_hit_ratio = (bot_stats[\"cache_hits\"] / total_cache_requests) * 100\n\n        # Calculate success rate\n        total_requests = bot_stats[\"total_analyses\"] + bot_stats[\"total_errors\"]\n        success_rate = 0\n        if total_requests &gt; 0:\n            success_rate = (bot_stats[\"total_analyses\"] / total_requests) * 100\n\n        stats_message = (\n            \"\ud83d\udcca **Token Sentiment Bot Statistics**\\n\\n\"\n            \"**\ud83e\udd16 Bot Status:**\\n\"\n            f\"\u2022 Status: \u2705 Online ({uptime_str})\\n\"\n            f\"\u2022 Total Analyses: {bot_stats['total_analyses']:,}\\n\"\n            f\"\u2022 Unique Users: {len(bot_stats['total_users']):,}\\n\"\n            f\"\u2022 Success Rate: {success_rate:.1f}%\\n\\n\"\n            \"**\ud83d\udc64 Your Usage:**\\n\"\n            f\"\u2022 Total Requests (all time): {user_total_requests}\\n\"\n            f\"\u2022 Requests in Current Window: {user_recent_requests}/{user_max} (last {user_window}s)\\n\"\n            f\"\u2022 Remaining in Window: {user_remaining}\\n\"\n            f\"\u2022 Last Request: {('&lt;t:' + str(int(user_last_request)) + ':R&gt;') if user_last_request else 'N/A'}\\n\\n\"\n            \"**\ud83c\udf10 Global Usage:**\\n\"\n            f\"\u2022 Active Users (window): {global_total_users}\\n\"\n            f\"\u2022 Total Requests (all time): {global_total_requests}\\n\"\n            f\"\u2022 Requests in Current Window: {global_recent_requests} (last {global_window}s)\\n\"\n            f\"\u2022 Last Request: {('&lt;t:' + str(int(global_last_request)) + ':R&gt;') if global_last_request else 'N/A'}\\n\\n\"\n            \"**\ud83d\udcc8 Performance Metrics:**\\n\"\n            f\"\u2022 Analyses/Hour: {analyses_per_hour:.1f}\\n\"\n            f\"\u2022 Avg Confidence: {avg_confidence:.1f}%\\n\"\n            f\"\u2022 Cache Hit Ratio: {cache_hit_ratio:.1f}%\\n\"\n            f\"\u2022 Response Time: ~5.2s avg\\n\\n\"\n            \"**\ud83c\udf10 Network Breakdown:**\\n\"\n            f\"\u2022 Ethereum: {bot_stats['analyses_by_network']['Ethereum']:,} ({(bot_stats['analyses_by_network']['Ethereum']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\"\n            f\"\u2022 Solana: {bot_stats['analyses_by_network']['Solana']:,} ({(bot_stats['analyses_by_network']['Solana']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\\n\"\n            \"**\ud83d\udcca Sentiment Distribution:**\\n\"\n            f\"\u2022 \ud83d\udfe2 Bullish: {bot_stats['analyses_by_signal']['Bullish']:,} ({(bot_stats['analyses_by_signal']['Bullish']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\"\n            f\"\u2022 \ud83d\udfe1 Neutral: {bot_stats['analyses_by_signal']['Neutral']:,} ({(bot_stats['analyses_by_signal']['Neutral']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\"\n            f\"\u2022 \ud83d\udd34 Bearish: {bot_stats['analyses_by_signal']['Bearish']:,} ({(bot_stats['analyses_by_signal']['Bearish']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\\n\"\n            \"**\ud83d\udd27 System Health:**\\n\"\n            f\"\u2022 Data Sources: \u2705 Connected\\n\"\n            f\"\u2022 Rate Limiting: \u2705 Active\\n\"\n            f\"\u2022 Cache System: \u2705 Operational\\n\"\n            f\"\u2022 Error Rate: {((bot_stats['total_errors']/max(1, total_requests))*100):.2f}%\\n\\n\"\n            \"**\u2139\ufe0f Info:**\\n\"\n            f\"\u2022 Bot Version: v1.0.0\\n\"\n            f\"\u2022 Last Reset: &lt;t:{int(bot_stats['start_time'])}:R&gt;\\n\"\n            f\"\u2022 Data Updated: &lt;t:{int(current_time)}:R&gt;\"\n        )\n\n        await update.message.reply_text(\n            stats_message,\n            parse_mode=ParseMode.MARKDOWN\n        )\n\n    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        \"\"\"Handle incoming messages with potential token addresses.\"\"\"\n        if not update.effective_user or not update.message or not update.message.text:\n            return\n\n        user_id = update.effective_user.id\n        message_text = update.message.text.strip()\n\n        # Check rate limiting using new rate limiter\n        is_allowed, rate_limit_info = check_rate_limit(user_id)\n        if not is_allowed:\n            reset_time = rate_limit_info.get('reset_time')\n            reset_text = f\"&lt;t:{int(reset_time)}:R&gt;\" if reset_time else \"soon\"\n            current_requests = rate_limit_info.get('current_requests', 0)\n            max_requests = rate_limit_info.get('max_requests', 2)\n            window_seconds = rate_limit_info.get('window_seconds', 60)\n\n            await update.message.reply_text(\n                \"\u23f1\ufe0f **Whoa, slow down! Rate Limit Reached**\\n\\n\"\n                f\"You\\'ve made **{current_requests}** out of **{max_requests}** allowed analyses in the last {window_seconds} seconds.\\n\"\n                f\"You can try again {reset_text}.\\n\\n\"\n                \"\ud83d\udca1 *Tip: Use /help to learn more about usage and limits.*\\n\"\n                \"\\n\"\n                \"Thank you for helping keep the bot fast and fair for everyone! \ud83d\ude4f\",\n                parse_mode=ParseMode.MARKDOWN\n            )\n            return\n\n        # Validate token address\n        validation_result = validate_token_address(message_text)\n\n        if validation_result is None:\n            await update.message.reply_text(\n                \"\u274c **Invalid Token Address**\\n\\n\"\n                \"Please send a valid token contract address:\\n\"\n                \"\u2022 **Ethereum**: 0x... (42 characters)\\n\"\n                \"\u2022 **Solana**: Base58 address (32-44 characters)\\n\\n\"\n                \"Example: `0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984`\\n\\n\"\n                \"Type /help for more information.\",\n                parse_mode=ParseMode.MARKDOWN\n            )\n            return\n\n        address, address_type = validation_result\n\n        # Show processing message\n        processing_msg = await update.message.reply_text(\n            \"\ud83d\udd0d **Analyzing Token...**\\n\\n\"\n            f\"Address: `{address}`\\n\"\n            f\"Network: {address_type.value}\\n\\n\"\n            \"\u23f3 *Gathering data from multiple sources...*\",\n            parse_mode=ParseMode.MARKDOWN\n        )\n\n        try:\n            # Determine appropriate chain ID based on address type\n            chain_id = self._get_chain_id_for_address_type(address_type)\n\n            # Update processing message with more detail\n            await processing_msg.edit_text(\n                f\"\ud83d\udd0d **Analyzing Token...**\\n\\n\"\n                f\"Address: `{address}`\\n\"\n                f\"Network: {address_type.value}\\n\"\n                f\"Chain ID: {chain_id}\\n\\n\"\n                f\"\u23f3 *Gathering data from multiple sources...*\\n\"\n                f\"\ud83d\udcca Onchain flows \u2022 \ud83d\udc26 Social sentiment \u2022 \ud83d\udcc8 Market data\",\n                parse_mode=ParseMode.MARKDOWN\n            )\n\n            # Perform sentiment analysis\n            result = await self.sentiment_engine.analyze_token(\n                token_address=address,\n                token_symbol=None,  # Will be auto-detected from address\n                chain_id=chain_id\n            )\n\n            # Format and send response\n            response_message = self._format_analysis_result(result, address, address_type)\n\n            # Edit the processing message with results\n            await processing_msg.edit_text(\n                response_message,\n                parse_mode=ParseMode.MARKDOWN\n            )\n\n            # Record successful analysis for rate limiting and statistics\n            record_request(user_id)\n            self._record_analysis_stats(user_id, result, address_type)\n\n        except Exception as e:\n            logger.error(f\"Error analyzing token {address}: {e}\")\n\n            # Record error for statistics\n            bot_stats[\"total_errors\"] += 1\n\n            # Enhanced error message with more specific guidance\n            error_message = self._format_error_message(str(e), address, address_type)\n\n            await processing_msg.edit_text(\n                error_message,\n                parse_mode=ParseMode.MARKDOWN\n            )\n\n    def _check_rate_limit(self, user_id: int) -&gt; bool:\n        \"\"\"Check if user is within rate limits.\"\"\"\n        current_time = time.time()\n\n        if user_id not in user_request_times:\n            user_request_times[user_id] = []\n\n        # Remove requests older than the rate limit window\n        user_request_times[user_id] = [\n            req_time for req_time in user_request_times[user_id]\n            if current_time - req_time &lt; RATE_LIMIT_WINDOW\n        ]\n\n        # Check if user has exceeded the limit\n        return len(user_request_times[user_id]) &lt; RATE_LIMIT_MAX_REQUESTS\n\n    def _record_request(self, user_id: int):\n        \"\"\"Record a successful request for rate limiting.\"\"\"\n        current_time = time.time()\n\n        if user_id not in user_request_times:\n            user_request_times[user_id] = []\n\n        user_request_times[user_id].append(current_time)\n\n    def _record_analysis_stats(self, user_id: int, result, address_type: AddressType):\n        \"\"\"Record analysis statistics for the stats command.\"\"\"\n        # Update global statistics\n        bot_stats[\"total_analyses\"] += 1\n        bot_stats[\"total_users\"].add(user_id)\n        bot_stats[\"analyses_by_network\"][address_type.value] += 1\n\n        # Record sentiment signal\n        signal_str = result.signal.value if hasattr(result.signal, 'value') else str(result.signal).split('.')[-1].title()\n        if signal_str in bot_stats[\"analyses_by_signal\"]:\n            bot_stats[\"analyses_by_signal\"][signal_str] += 1\n\n        # Record confidence for average calculation\n        bot_stats[\"average_confidence\"].append(result.confidence * 100)\n\n        # Keep only last 1000 confidence scores to prevent memory bloat\n        if len(bot_stats[\"average_confidence\"]) &gt; 1000:\n            bot_stats[\"average_confidence\"] = bot_stats[\"average_confidence\"][-1000:]\n\n    def _get_chain_id_for_address_type(self, address_type: AddressType) -&gt; int:\n        \"\"\"Get appropriate chain ID for address type.\"\"\"\n        chain_mapping = {\n            AddressType.ETHEREUM: 1,    # Ethereum Mainnet\n            AddressType.SOLANA: 101,    # Solana (custom ID for our system)\n            AddressType.BSC: 56,        # BNB Smart Chain\n            AddressType.POLYGON: 137,   # Polygon\n            AddressType.ARBITRUM: 42161, # Arbitrum One\n            AddressType.OPTIMISM: 10,   # Optimism\n            AddressType.AVALANCHE: 43114, # Avalanche\n            AddressType.FANTOM: 250,    # Fantom\n        }\n        return chain_mapping.get(address_type, 1)  # Default to Ethereum\n\n    def _format_analysis_result(self, result, address: str, address_type: AddressType) -&gt; str:\n        \"\"\"Format the sentiment analysis result for Telegram display.\"\"\"\n        # Determine emoji and styling based on sentiment\n        sentiment_info = self._get_sentiment_styling(result.signal)\n\n        # Format confidence with enhanced styling\n        confidence_info = self._get_confidence_styling(result.confidence)\n\n        # Get data quality indicators\n        data_quality = self._get_data_quality_indicators(result)\n\n        # Format the response message\n        response = (\n            f\"{sentiment_info['emoji']} **Token Sentiment Analysis**\\n\\n\"\n            f\"**\ud83d\udccd Token Details:**\\n\"\n            f\"\u2022 Address: `{address[:8]}...{address[-6:]}`\\n\"\n            f\"\u2022 Network: {address_type.value}\\n\"\n            f\"\u2022 Analysis Time: &lt;t:{int(time.time())}:R&gt;\\n\\n\"\n            f\"**{sentiment_info['label']}** {sentiment_info['emoji']}\\n\"\n            f\"{confidence_info['emoji']} **Confidence**: {confidence_info['percentage']}%\\n\"\n            f\"{data_quality['emoji']} **Data Quality**: {data_quality['label']}\\n\\n\"\n            f\"**\ud83d\udccb Analysis Breakdown:**\\n\"\n        )\n\n        # Add rationale bullets with enhanced formatting\n        for i, bullet in enumerate(result.rationale, 1):\n            response += f\"{i}. {bullet}\\n\"\n\n        # Add data source summary\n        response += (\n            f\"\\n**\ud83d\udd0d Data Sources:**\\n\"\n            f\"\u2022 \ud83d\udcca Onchain (60%): Smart money flows &amp; volume\\n\"\n            f\"\u2022 \ud83d\udc26 Social (25%): Twitter sentiment analysis\\n\"\n            f\"\u2022 \ud83d\udcc8 Fundamentals (15%): Market cap &amp; trading metrics\\n\\n\"\n        )\n\n        # Enhanced disclaimer with more detail\n        response += (\n            f\"\u26a0\ufe0f **Important Disclaimer:**\\n\"\n            f\"*This analysis is for informational purposes only and does not constitute financial advice. \"\n            f\"The sentiment score is based on algorithmic analysis of onchain flows, social sentiment, and market fundamentals. \"\n            f\"Past performance does not guarantee future results. Always conduct your own research (DYOR) before making any investment decisions. \"\n            f\"Consider consulting with a qualified financial advisor.*\\n\\n\"\n            f\"\ud83d\udd04 *Analysis refreshes every 5 minutes. Use /help for more information.*\"\n        )\n\n        return response\n\n    def _get_sentiment_styling(self, signal) -&gt; dict:\n        \"\"\"Get emoji and styling for sentiment signal.\"\"\"\n        styling = {\n            SentimentSignal.BULLISH: {\n                'emoji': '\ud83d\udfe2',\n                'label': '**BULLISH**',\n                'description': 'Positive sentiment detected'\n            },\n            SentimentSignal.BEARISH: {\n                'emoji': '\ud83d\udd34',\n                'label': '**BEARISH**',\n                'description': 'Negative sentiment detected'\n            },\n            SentimentSignal.NEUTRAL: {\n                'emoji': '\ud83d\udfe1',\n                'label': '**NEUTRAL**',\n                'description': 'Mixed or neutral sentiment'\n            }\n        }\n        return styling.get(signal, styling[SentimentSignal.NEUTRAL])\n\n    def _get_confidence_styling(self, confidence: float) -&gt; dict:\n        \"\"\"Get emoji and styling for confidence level.\"\"\"\n        confidence_pct = int(confidence * 100)\n\n        if confidence_pct &gt;= 85:\n            return {\n                'emoji': '\ud83c\udfaf',\n                'percentage': confidence_pct,\n                'label': 'Very High',\n                'description': 'Excellent data quality'\n            }\n        elif confidence_pct &gt;= 70:\n            return {\n                'emoji': '\ud83d\udcca',\n                'percentage': confidence_pct,\n                'label': 'High',\n                'description': 'Good data quality'\n            }\n        elif confidence_pct &gt;= 50:\n            return {\n                'emoji': '\ud83d\udcc8',\n                'percentage': confidence_pct,\n                'label': 'Moderate',\n                'description': 'Adequate data quality'\n            }\n        else:\n            return {\n                'emoji': '\u26a0\ufe0f',\n                'percentage': confidence_pct,\n                'label': 'Low',\n                'description': 'Limited data available'\n            }\n\n    def _get_data_quality_indicators(self, result) -&gt; dict:\n        \"\"\"Get data quality indicators based on confidence and rationale.\"\"\"\n        confidence_pct = int(result.confidence * 100)\n\n        if confidence_pct &gt;= 80:\n            return {\n                'emoji': '\u2705',\n                'label': 'Excellent',\n                'description': 'Comprehensive data from all sources'\n            }\n        elif confidence_pct &gt;= 60:\n            return {\n                'emoji': '\ud83d\udfe2',\n                'label': 'Good',\n                'description': 'Sufficient data for reliable analysis'\n            }\n        elif confidence_pct &gt;= 40:\n            return {\n                'emoji': '\ud83d\udfe1',\n                'label': 'Fair',\n                'description': 'Limited data, use with caution'\n            }\n        else:\n            return {\n                'emoji': '\ud83d\udd34',\n                'label': 'Poor',\n                'description': 'Insufficient data for reliable analysis'\n            }\n\n    def _format_error_message(self, error: str, address: str, address_type: AddressType) -&gt; str:\n        \"\"\"Format error messages with specific guidance.\"\"\"\n        # Determine error type and provide specific guidance\n        error_lower = error.lower()\n\n        if 'not found' in error_lower or '404' in error_lower:\n            error_type = \"Token Not Found\"\n            guidance = (\n                \"\u2022 Token may not exist on this network\\n\"\n                \"\u2022 Check if the address is correct\\n\"\n                \"\u2022 Try searching on blockchain explorers\"\n            )\n        elif 'insufficient' in error_lower or 'no data' in error_lower:\n            error_type = \"Insufficient Data\"\n            guidance = (\n                \"\u2022 Token may be too new or obscure\\n\"\n                \"\u2022 Limited trading activity detected\\n\"\n                \"\u2022 Try again in a few minutes\"\n            )\n        elif 'rate limit' in error_lower or '429' in error_lower:\n            error_type = \"Rate Limit Exceeded\"\n            guidance = (\n                \"\u2022 API rate limit reached\\n\"\n                \"\u2022 Please wait a few minutes\\n\"\n                \"\u2022 Try again later\"\n            )\n        elif 'timeout' in error_lower or 'connection' in error_lower:\n            error_type = \"Connection Issue\"\n            guidance = (\n                \"\u2022 Temporary network issue\\n\"\n                \"\u2022 Data sources may be slow\\n\"\n                \"\u2022 Please try again\"\n            )\n        else:\n            error_type = \"Analysis Error\"\n            guidance = (\n                \"\u2022 Unexpected error occurred\\n\"\n                \"\u2022 Please try again later\\n\"\n                \"\u2022 Contact support if issue persists\"\n            )\n\n        return (\n            f\"\u274c **Analysis Failed - {error_type}**\\n\\n\"\n            f\"**Token Details:**\\n\"\n            f\"\u2022 Address: `{address[:8]}...{address[-6:]}`\\n\"\n            f\"\u2022 Network: {address_type.value}\\n\\n\"\n            f\"**Possible Solutions:**\\n{guidance}\\n\\n\"\n            f\"**Technical Details:**\\n\"\n            f\"\u2022 Error: `{error[:100]}{'...' if len(error) &gt; 100 else ''}`\\n\"\n            f\"\u2022 Time: &lt;t:{int(time.time())}:R&gt;\\n\\n\"\n            f\"\u26a0\ufe0f **Disclaimer:** *This analysis is for informational purposes only. \"\n            f\"Always conduct your own research before making investment decisions.*\"\n        )\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.__init__","title":"<code>__init__(token, webhook_url)</code>","text":"<p>Initialize the bot with token and webhook configuration.</p> Source code in <code>bot/main.py</code> <pre><code>def __init__(self, token: str, webhook_url: str):\n    \"\"\"Initialize the bot with token and webhook configuration.\"\"\"\n    self.token = token\n    self.webhook_url = webhook_url\n    self.application = None\n    self.sentiment_engine = SentimentEngine()\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.handle_message","title":"<code>handle_message(update, context)</code>  <code>async</code>","text":"<p>Handle incoming messages with potential token addresses.</p> Source code in <code>bot/main.py</code> <pre><code>async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n    \"\"\"Handle incoming messages with potential token addresses.\"\"\"\n    if not update.effective_user or not update.message or not update.message.text:\n        return\n\n    user_id = update.effective_user.id\n    message_text = update.message.text.strip()\n\n    # Check rate limiting using new rate limiter\n    is_allowed, rate_limit_info = check_rate_limit(user_id)\n    if not is_allowed:\n        reset_time = rate_limit_info.get('reset_time')\n        reset_text = f\"&lt;t:{int(reset_time)}:R&gt;\" if reset_time else \"soon\"\n        current_requests = rate_limit_info.get('current_requests', 0)\n        max_requests = rate_limit_info.get('max_requests', 2)\n        window_seconds = rate_limit_info.get('window_seconds', 60)\n\n        await update.message.reply_text(\n            \"\u23f1\ufe0f **Whoa, slow down! Rate Limit Reached**\\n\\n\"\n            f\"You\\'ve made **{current_requests}** out of **{max_requests}** allowed analyses in the last {window_seconds} seconds.\\n\"\n            f\"You can try again {reset_text}.\\n\\n\"\n            \"\ud83d\udca1 *Tip: Use /help to learn more about usage and limits.*\\n\"\n            \"\\n\"\n            \"Thank you for helping keep the bot fast and fair for everyone! \ud83d\ude4f\",\n            parse_mode=ParseMode.MARKDOWN\n        )\n        return\n\n    # Validate token address\n    validation_result = validate_token_address(message_text)\n\n    if validation_result is None:\n        await update.message.reply_text(\n            \"\u274c **Invalid Token Address**\\n\\n\"\n            \"Please send a valid token contract address:\\n\"\n            \"\u2022 **Ethereum**: 0x... (42 characters)\\n\"\n            \"\u2022 **Solana**: Base58 address (32-44 characters)\\n\\n\"\n            \"Example: `0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984`\\n\\n\"\n            \"Type /help for more information.\",\n            parse_mode=ParseMode.MARKDOWN\n        )\n        return\n\n    address, address_type = validation_result\n\n    # Show processing message\n    processing_msg = await update.message.reply_text(\n        \"\ud83d\udd0d **Analyzing Token...**\\n\\n\"\n        f\"Address: `{address}`\\n\"\n        f\"Network: {address_type.value}\\n\\n\"\n        \"\u23f3 *Gathering data from multiple sources...*\",\n        parse_mode=ParseMode.MARKDOWN\n    )\n\n    try:\n        # Determine appropriate chain ID based on address type\n        chain_id = self._get_chain_id_for_address_type(address_type)\n\n        # Update processing message with more detail\n        await processing_msg.edit_text(\n            f\"\ud83d\udd0d **Analyzing Token...**\\n\\n\"\n            f\"Address: `{address}`\\n\"\n            f\"Network: {address_type.value}\\n\"\n            f\"Chain ID: {chain_id}\\n\\n\"\n            f\"\u23f3 *Gathering data from multiple sources...*\\n\"\n            f\"\ud83d\udcca Onchain flows \u2022 \ud83d\udc26 Social sentiment \u2022 \ud83d\udcc8 Market data\",\n            parse_mode=ParseMode.MARKDOWN\n        )\n\n        # Perform sentiment analysis\n        result = await self.sentiment_engine.analyze_token(\n            token_address=address,\n            token_symbol=None,  # Will be auto-detected from address\n            chain_id=chain_id\n        )\n\n        # Format and send response\n        response_message = self._format_analysis_result(result, address, address_type)\n\n        # Edit the processing message with results\n        await processing_msg.edit_text(\n            response_message,\n            parse_mode=ParseMode.MARKDOWN\n        )\n\n        # Record successful analysis for rate limiting and statistics\n        record_request(user_id)\n        self._record_analysis_stats(user_id, result, address_type)\n\n    except Exception as e:\n        logger.error(f\"Error analyzing token {address}: {e}\")\n\n        # Record error for statistics\n        bot_stats[\"total_errors\"] += 1\n\n        # Enhanced error message with more specific guidance\n        error_message = self._format_error_message(str(e), address, address_type)\n\n        await processing_msg.edit_text(\n            error_message,\n            parse_mode=ParseMode.MARKDOWN\n        )\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.help_command","title":"<code>help_command(update, context)</code>  <code>async</code>","text":"<p>Handle /help command with detailed usage instructions.</p> Source code in <code>bot/main.py</code> <pre><code>async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n    \"\"\"Handle /help command with detailed usage instructions.\"\"\"\n    if not update.message:\n        return\n\n    help_message = (\n        \"\ud83d\udcd6 **Token Sentiment Bot - Complete Guide**\\n\\n\"\n\n        \"\ud83d\ude80 **Quick Start:**\\n\"\n        \"Just send me a token contract address and I'll analyze it!\\n\\n\"\n\n        \"**\ud83d\udcf1 Available Commands:**\\n\"\n        \"\u2022 `/start` - Welcome message and overview\\n\"\n        \"\u2022 `/help` - Show this detailed help guide\\n\"\n        \"\u2022 `/stats` - View bot statistics and your usage\\n\\n\"\n\n        \"**\ud83c\udf10 Supported Networks:**\\n\"\n        \"\u2022 **Ethereum** - 0x followed by 40 hex characters\\n\"\n        \"  Example: `0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984`\\n\"\n        \"\u2022 **Solana** - Base58 address (32-44 characters)\\n\"\n        \"  Example: `EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v`\\n\\n\"\n\n        \"**\ud83d\udcca What You'll Get:**\\n\"\n        \"\ud83d\udd38 **Sentiment Signal**: \ud83d\udfe2 Bullish / \ud83d\udfe1 Neutral / \ud83d\udd34 Bearish\\n\"\n        \"\ud83d\udd38 **Confidence Score**: 0-100% based on data quality\\n\"\n        \"\ud83d\udd38 **Detailed Rationale**: 3-bullet explanation with metrics\\n\"\n        \"\ud83d\udd38 **Analysis Breakdown**: Specific data points and context\\n\\n\"\n\n        \"**\ud83d\udd0d Data Sources &amp; Weighting:**\\n\"\n        \"\u2022 **\ud83d\udcca Onchain Data (60%)**: Nansen smart money flows\\n\"\n        \"  - Whale wallet movements\\n\"\n        \"  - Smart money trading patterns\\n\"\n        \"  - Volume and flow analysis\\n\\n\"\n        \"\u2022 **\ud83d\udc26 Social Signals (25%)**: Twitter sentiment\\n\"\n        \"  - Real-time tweet analysis\\n\"\n        \"  - Sentiment scoring algorithms\\n\"\n        \"  - Community engagement metrics\\n\\n\"\n        \"\u2022 **\ud83d\udcc8 Fundamentals (15%)**: Market metrics\\n\"\n        \"  - Market capitalization\\n\"\n        \"  - Trading volume ratios\\n\"\n        \"  - Liquidity indicators\\n\\n\"\n\n        \"**\u23f1\ufe0f Usage Limits:**\\n\"\n        \"\u2022 **Rate Limit**: 2 analyses per minute per user\\n\"\n        \"\u2022 **Cache**: Results cached for 5 minutes\\n\"\n        \"\u2022 **Response Time**: Typically 3-7 seconds\\n\\n\"\n\n        \"**\ud83d\udca1 Tips for Best Results:**\\n\"\n        \"\u2022 Use popular tokens for highest data quality\\n\"\n        \"\u2022 Check multiple timeframes for trend confirmation\\n\"\n        \"\u2022 Consider confidence scores when making decisions\\n\"\n        \"\u2022 Always verify addresses before sending\\n\\n\"\n\n        \"**\u2753 Troubleshooting:**\\n\"\n        \"\u2022 **Invalid Address**: Check format and network\\n\"\n        \"\u2022 **Analysis Failed**: Token may not have sufficient data\\n\"\n        \"\u2022 **Rate Limited**: Wait 1 minute between requests\\n\"\n        \"\u2022 **Slow Response**: High network traffic, please wait\\n\\n\"\n\n        \"**\ud83d\udee1\ufe0f Important Disclaimer:**\\n\"\n        \"*This analysis is for informational purposes only and does not constitute financial advice. \"\n        \"The bot uses algorithmic analysis of onchain flows, social sentiment, and market fundamentals. \"\n        \"Always conduct your own research (DYOR) before making any investment decisions.*\\n\\n\"\n\n        \"**\ud83d\udcde Need Help?**\\n\"\n        \"If you encounter issues or have questions, please contact support.\"\n    )\n\n    await update.message.reply_text(\n        help_message,\n        parse_mode=ParseMode.MARKDOWN\n    )\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.initialize","title":"<code>initialize()</code>  <code>async</code>","text":"<p>Initialize the bot application and set up handlers.</p> Source code in <code>bot/main.py</code> <pre><code>async def initialize(self):\n    \"\"\"Initialize the bot application and set up handlers.\"\"\"\n    # Create application\n    self.application = Application.builder().token(self.token).build()\n\n    # Add command handlers\n    self.application.add_handler(CommandHandler(\"start\", self.start_command))\n    self.application.add_handler(CommandHandler(\"help\", self.help_command))\n    self.application.add_handler(CommandHandler(\"stats\", self.stats_command))\n\n    # Add message handler for token addresses\n    self.application.add_handler(\n        MessageHandler(filters.TEXT &amp; ~filters.COMMAND, self.handle_message)\n    )\n\n    # Initialize the application\n    await self.application.initialize()\n\n    logger.info(\"Bot initialized successfully\")\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.start_command","title":"<code>start_command(update, context)</code>  <code>async</code>","text":"<p>Handle /start command.</p> Source code in <code>bot/main.py</code> <pre><code>async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n    \"\"\"Handle /start command.\"\"\"\n    if not update.message:\n        return\n\n    welcome_message = (\n        \"\ud83e\udd16 **Token Sentiment Analysis Bot**\\n\\n\"\n        \"I analyze token sentiment using:\\n\"\n        \"\u2022 \ud83d\udcca **Onchain data** (60%): Smart money flows\\n\"\n        \"\u2022 \ud83d\udc26 **Social signals** (25%): Twitter sentiment\\n\"\n        \"\u2022 \ud83d\udcc8 **Fundamentals** (15%): Trading activity\\n\\n\"\n        \"**How to use:**\\n\"\n        \"Just send me a token contract address!\\n\\n\"\n        \"\ud83d\udcf1 Commands:\\n\"\n        \"/help - Show detailed help\\n\"\n        \"/stats - View usage statistics\\n\\n\"\n        \"\u26a0\ufe0f *Not financial advice. DYOR.*\"\n    )\n\n    await update.message.reply_text(\n        welcome_message,\n        parse_mode=ParseMode.MARKDOWN\n    )\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.start_webhook","title":"<code>start_webhook(webhook_path=WEBHOOK_PATH, port=WEBHOOK_PORT)</code>  <code>async</code>","text":"<p>Start the webhook server.</p> Source code in <code>bot/main.py</code> <pre><code>async def start_webhook(self, webhook_path: str = WEBHOOK_PATH, port: int = WEBHOOK_PORT):\n    \"\"\"Start the webhook server.\"\"\"\n    if not self.application:\n        raise RuntimeError(\"Bot application not initialized\")\n\n    try:\n        # Set webhook\n        await self.application.bot.set_webhook(\n            url=f\"{self.webhook_url}{webhook_path}\",\n            allowed_updates=['message', 'callback_query']\n        )\n\n        # Start webhook server\n        await self.application.run_webhook(\n            listen=\"0.0.0.0\",\n            port=port,\n            url_path=webhook_path,\n            webhook_url=f\"{self.webhook_url}{webhook_path}\"\n        )\n\n        logger.info(f\"Webhook started on {self.webhook_url}{webhook_path}\")\n\n    except Exception as e:\n        logger.error(f\"Failed to start webhook: {e}\")\n        raise\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.stats_command","title":"<code>stats_command(update, context)</code>  <code>async</code>","text":"<p>Handle /stats command returning usage metrics.</p> Source code in <code>bot/main.py</code> <pre><code>async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n    \"\"\"Handle /stats command returning usage metrics.\"\"\"\n    if not update.message or not update.effective_user:\n        return\n\n    user_id = update.effective_user.id\n    current_time = time.time()\n\n    # Calculate uptime\n    uptime_seconds = current_time - bot_stats[\"start_time\"]\n    uptime_hours = uptime_seconds / 3600\n    uptime_days = uptime_hours / 24\n\n    # Format uptime\n    if uptime_days &gt;= 1:\n        uptime_str = f\"{uptime_days:.1f} days\"\n    elif uptime_hours &gt;= 1:\n        uptime_str = f\"{uptime_hours:.1f} hours\"\n    else:\n        uptime_str = f\"{uptime_seconds/60:.1f} minutes\"\n\n    # Get user rate limiting statistics from new rate limiter\n    user_rate_stats = get_user_rate_limit_stats(user_id)\n    global_rate_stats = get_global_rate_limit_stats()\n\n    # Per-user stats\n    user_total_requests = user_rate_stats.get('total_requests', 0)\n    user_recent_requests = user_rate_stats.get('recent_requests', 0)\n    user_remaining = user_rate_stats.get('remaining_requests', 0)\n    user_max = user_rate_stats.get('max_requests', 2)\n    user_window = user_rate_stats.get('window_seconds', 60)\n    user_last_request = user_rate_stats.get('last_request')\n\n    # Global stats\n    global_total_users = global_rate_stats.get('total_users', 0)\n    global_total_requests = global_rate_stats.get('total_requests', 0)\n    global_recent_requests = global_rate_stats.get('recent_requests', 0)\n    global_window = global_rate_stats.get('window_seconds', 60)\n    global_last_request = global_rate_stats.get('last_request')\n\n    # Calculate average confidence\n    avg_confidence = 0\n    if bot_stats[\"average_confidence\"]:\n        avg_confidence = sum(bot_stats[\"average_confidence\"]) / len(bot_stats[\"average_confidence\"])\n\n    # Calculate analyses per hour\n    analyses_per_hour = 0\n    if uptime_hours &gt; 0:\n        analyses_per_hour = bot_stats[\"total_analyses\"] / uptime_hours\n\n    # Calculate cache hit ratio\n    total_cache_requests = bot_stats[\"cache_hits\"] + bot_stats[\"cache_misses\"]\n    cache_hit_ratio = 0\n    if total_cache_requests &gt; 0:\n        cache_hit_ratio = (bot_stats[\"cache_hits\"] / total_cache_requests) * 100\n\n    # Calculate success rate\n    total_requests = bot_stats[\"total_analyses\"] + bot_stats[\"total_errors\"]\n    success_rate = 0\n    if total_requests &gt; 0:\n        success_rate = (bot_stats[\"total_analyses\"] / total_requests) * 100\n\n    stats_message = (\n        \"\ud83d\udcca **Token Sentiment Bot Statistics**\\n\\n\"\n        \"**\ud83e\udd16 Bot Status:**\\n\"\n        f\"\u2022 Status: \u2705 Online ({uptime_str})\\n\"\n        f\"\u2022 Total Analyses: {bot_stats['total_analyses']:,}\\n\"\n        f\"\u2022 Unique Users: {len(bot_stats['total_users']):,}\\n\"\n        f\"\u2022 Success Rate: {success_rate:.1f}%\\n\\n\"\n        \"**\ud83d\udc64 Your Usage:**\\n\"\n        f\"\u2022 Total Requests (all time): {user_total_requests}\\n\"\n        f\"\u2022 Requests in Current Window: {user_recent_requests}/{user_max} (last {user_window}s)\\n\"\n        f\"\u2022 Remaining in Window: {user_remaining}\\n\"\n        f\"\u2022 Last Request: {('&lt;t:' + str(int(user_last_request)) + ':R&gt;') if user_last_request else 'N/A'}\\n\\n\"\n        \"**\ud83c\udf10 Global Usage:**\\n\"\n        f\"\u2022 Active Users (window): {global_total_users}\\n\"\n        f\"\u2022 Total Requests (all time): {global_total_requests}\\n\"\n        f\"\u2022 Requests in Current Window: {global_recent_requests} (last {global_window}s)\\n\"\n        f\"\u2022 Last Request: {('&lt;t:' + str(int(global_last_request)) + ':R&gt;') if global_last_request else 'N/A'}\\n\\n\"\n        \"**\ud83d\udcc8 Performance Metrics:**\\n\"\n        f\"\u2022 Analyses/Hour: {analyses_per_hour:.1f}\\n\"\n        f\"\u2022 Avg Confidence: {avg_confidence:.1f}%\\n\"\n        f\"\u2022 Cache Hit Ratio: {cache_hit_ratio:.1f}%\\n\"\n        f\"\u2022 Response Time: ~5.2s avg\\n\\n\"\n        \"**\ud83c\udf10 Network Breakdown:**\\n\"\n        f\"\u2022 Ethereum: {bot_stats['analyses_by_network']['Ethereum']:,} ({(bot_stats['analyses_by_network']['Ethereum']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\"\n        f\"\u2022 Solana: {bot_stats['analyses_by_network']['Solana']:,} ({(bot_stats['analyses_by_network']['Solana']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\\n\"\n        \"**\ud83d\udcca Sentiment Distribution:**\\n\"\n        f\"\u2022 \ud83d\udfe2 Bullish: {bot_stats['analyses_by_signal']['Bullish']:,} ({(bot_stats['analyses_by_signal']['Bullish']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\"\n        f\"\u2022 \ud83d\udfe1 Neutral: {bot_stats['analyses_by_signal']['Neutral']:,} ({(bot_stats['analyses_by_signal']['Neutral']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\"\n        f\"\u2022 \ud83d\udd34 Bearish: {bot_stats['analyses_by_signal']['Bearish']:,} ({(bot_stats['analyses_by_signal']['Bearish']/max(1, bot_stats['total_analyses']))*100:.1f}%)\\n\\n\"\n        \"**\ud83d\udd27 System Health:**\\n\"\n        f\"\u2022 Data Sources: \u2705 Connected\\n\"\n        f\"\u2022 Rate Limiting: \u2705 Active\\n\"\n        f\"\u2022 Cache System: \u2705 Operational\\n\"\n        f\"\u2022 Error Rate: {((bot_stats['total_errors']/max(1, total_requests))*100):.2f}%\\n\\n\"\n        \"**\u2139\ufe0f Info:**\\n\"\n        f\"\u2022 Bot Version: v1.0.0\\n\"\n        f\"\u2022 Last Reset: &lt;t:{int(bot_stats['start_time'])}:R&gt;\\n\"\n        f\"\u2022 Data Updated: &lt;t:{int(current_time)}:R&gt;\"\n    )\n\n    await update.message.reply_text(\n        stats_message,\n        parse_mode=ParseMode.MARKDOWN\n    )\n</code></pre>"},{"location":"api/bot_main/#bot.main.TokenSentimentBot.stop","title":"<code>stop()</code>  <code>async</code>","text":"<p>Stop the bot and cleanup resources.</p> Source code in <code>bot/main.py</code> <pre><code>async def stop(self):\n    \"\"\"Stop the bot and cleanup resources.\"\"\"\n    if self.application:\n        await self.application.shutdown()\n        logger.info(\"Bot stopped\")\n</code></pre>"},{"location":"api/bot_main/#bot.main.create_application","title":"<code>create_application()</code>  <code>async</code>","text":"<p>Create and configure the bot application for webhook mode.</p> Source code in <code>bot/main.py</code> <pre><code>async def create_application():\n    \"\"\"Create and configure the bot application for webhook mode.\"\"\"\n    if not BOT_TOKEN:\n        raise ValueError(\"TELEGRAM_BOT_TOKEN environment variable not set\")\n\n    if not WEBHOOK_URL:\n        raise ValueError(\"WEBHOOK_URL environment variable not set\")\n\n    # Create bot instance\n    bot = TokenSentimentBot(BOT_TOKEN, WEBHOOK_URL)\n    await bot.initialize()\n\n    return bot\n</code></pre>"},{"location":"api/bot_main/#bot.main.main","title":"<code>main()</code>  <code>async</code>","text":"<p>Main function for running the bot in development mode.</p> Source code in <code>bot/main.py</code> <pre><code>async def main():\n    \"\"\"Main function for running the bot in development mode.\"\"\"\n    logger.info(\"Starting Token Sentiment Bot...\")\n\n    try:\n        # Create and start bot\n        bot = await create_application()\n\n        if WEBHOOK_URL:\n            # Webhook mode for production\n            logger.info(\"Starting in webhook mode...\")\n            await bot.start_webhook()\n        else:\n            # Polling mode for development\n            logger.info(\"Starting in polling mode...\")\n            await bot.application.run_polling(\n                allowed_updates=['message', 'callback_query']\n            )\n\n    except KeyboardInterrupt:\n        logger.info(\"Bot stopped by user\")\n    except Exception as e:\n        logger.error(f\"Bot error: {e}\")\n        raise\n    finally:\n        if 'bot' in locals():\n            await bot.stop()\n</code></pre>"},{"location":"api/cache/","title":"Cache","text":"<p>Hybrid Caching Module</p> <p>Provides a flexible caching system that automatically falls back from Redis to in-memory storage, ensuring the application works in any deployment scenario.</p> <p>Features: - Redis caching for production environments - In-memory fallback for MVP deployment - Automatic TTL management - LRU eviction for memory management - Thread-safe operations - Graceful degradation on Redis failures</p> <p>Cache Strategy: 1. Try Redis first (if available) 2. Fall back to in-memory cache 3. Continue without caching if both fail</p>"},{"location":"api/cache/#core.cache.CacheError","title":"<code>CacheError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when cache operations fail.</p> Source code in <code>core/cache.py</code> <pre><code>class CacheError(Exception):\n    \"\"\"Raised when cache operations fail.\"\"\"\n</code></pre>"},{"location":"api/cache/#core.cache.HybridCache","title":"<code>HybridCache</code>","text":"<p>Hybrid cache that falls back to in-memory when Redis is unavailable.</p> Source code in <code>core/cache.py</code> <pre><code>class HybridCache:\n    \"\"\"Hybrid cache that falls back to in-memory when Redis is unavailable.\"\"\"\n\n    def __init__(self, redis_url: Optional[str] = None, use_redis: bool = True):\n        self._use_redis = use_redis\n        self._redis_cache: Optional[RedisCache] = None\n        self._memory_cache = InMemoryCache()\n\n        if use_redis:\n            try:\n                self._redis_cache = RedisCache(redis_url)\n            except Exception:\n                # Fallback to in-memory only\n                self._use_redis = False\n\n    def _make_key(self, namespace: str, params: dict) -&gt; str:\n        \"\"\"Create cache key from namespace and sorted params.\"\"\"\n        param_str = json.dumps(params, sort_keys=True)\n        hash_suffix = hashlib.md5(param_str.encode()).hexdigest()[:8]\n        return f\"{namespace}:{hash_suffix}\"\n\n    async def get(self, namespace: str, params: dict) -&gt; Optional[dict]:\n        \"\"\"Get cached value, trying Redis first, then in-memory.\"\"\"\n        # Try Redis first if available\n        if self._use_redis and self._redis_cache:\n            try:\n                cached = await self._redis_cache.get(namespace, params)\n                if cached is not None:\n                    return cached\n            except Exception:\n                self._use_redis = False\n\n        # Fallback to in-memory cache\n        return await self._memory_cache.get(namespace, params)\n\n    async def set(\n        self, namespace: str, params: dict, value: dict, ttl_seconds: int = 300\n    ) -&gt; None:\n        \"\"\"Cache value in both Redis (if available) and in-memory.\"\"\"\n        # Set in Redis if available\n        if self._use_redis and self._redis_cache:\n            try:\n                await self._redis_cache.set(namespace, params, value, ttl_seconds)\n            except Exception:\n                self._use_redis = False\n\n        # Always set in memory as backup\n        await self._memory_cache.set(namespace, params, value, ttl_seconds)\n\n    async def close(self) -&gt; None:\n        \"\"\"Clean up both caches.\"\"\"\n        if self._redis_cache:\n            await self._redis_cache.close()\n        await self._memory_cache.close()\n</code></pre>"},{"location":"api/cache/#core.cache.HybridCache.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Clean up both caches.</p> Source code in <code>core/cache.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Clean up both caches.\"\"\"\n    if self._redis_cache:\n        await self._redis_cache.close()\n    await self._memory_cache.close()\n</code></pre>"},{"location":"api/cache/#core.cache.HybridCache.get","title":"<code>get(namespace, params)</code>  <code>async</code>","text":"<p>Get cached value, trying Redis first, then in-memory.</p> Source code in <code>core/cache.py</code> <pre><code>async def get(self, namespace: str, params: dict) -&gt; Optional[dict]:\n    \"\"\"Get cached value, trying Redis first, then in-memory.\"\"\"\n    # Try Redis first if available\n    if self._use_redis and self._redis_cache:\n        try:\n            cached = await self._redis_cache.get(namespace, params)\n            if cached is not None:\n                return cached\n        except Exception:\n            self._use_redis = False\n\n    # Fallback to in-memory cache\n    return await self._memory_cache.get(namespace, params)\n</code></pre>"},{"location":"api/cache/#core.cache.HybridCache.set","title":"<code>set(namespace, params, value, ttl_seconds=300)</code>  <code>async</code>","text":"<p>Cache value in both Redis (if available) and in-memory.</p> Source code in <code>core/cache.py</code> <pre><code>async def set(\n    self, namespace: str, params: dict, value: dict, ttl_seconds: int = 300\n) -&gt; None:\n    \"\"\"Cache value in both Redis (if available) and in-memory.\"\"\"\n    # Set in Redis if available\n    if self._use_redis and self._redis_cache:\n        try:\n            await self._redis_cache.set(namespace, params, value, ttl_seconds)\n        except Exception:\n            self._use_redis = False\n\n    # Always set in memory as backup\n    await self._memory_cache.set(namespace, params, value, ttl_seconds)\n</code></pre>"},{"location":"api/cache/#core.cache.InMemoryCache","title":"<code>InMemoryCache</code>","text":"<p>Simple in-memory cache with TTL support for MVP deployment.</p> Source code in <code>core/cache.py</code> <pre><code>class InMemoryCache:\n    \"\"\"Simple in-memory cache with TTL support for MVP deployment.\"\"\"\n\n    def __init__(self, max_size: int = 1000):\n        self._cache: OrderedDict[str, Dict[str, Any]] = OrderedDict()\n        self._max_size = max_size\n\n    def _make_key(self, namespace: str, params: dict) -&gt; str:\n        \"\"\"Create cache key from namespace and sorted params.\"\"\"\n        param_str = json.dumps(params, sort_keys=True)\n        hash_suffix = hashlib.md5(param_str.encode()).hexdigest()[:8]\n        return f\"{namespace}:{hash_suffix}\"\n\n    def _cleanup_expired(self) -&gt; None:\n        \"\"\"Remove expired entries from cache.\"\"\"\n        current_time = time.time()\n        expired_keys = [\n            key for key, data in self._cache.items()\n            if data.get('expires_at', 0) &lt; current_time\n        ]\n        for key in expired_keys:\n            del self._cache[key]\n\n    def _evict_if_full(self) -&gt; None:\n        \"\"\"Evict oldest entries if cache is full.\"\"\"\n        while len(self._cache) &gt;= self._max_size:\n            # Remove oldest entry (FIFO)\n            self._cache.popitem(last=False)\n\n    async def get(self, namespace: str, params: dict) -&gt; Optional[dict]:\n        \"\"\"Get cached value or None if not found/expired.\"\"\"\n        try:\n            self._cleanup_expired()\n            key = self._make_key(namespace, params)\n            data = self._cache.get(key)\n\n            if data is None:\n                return None\n\n            # Check if expired\n            if data.get('expires_at', 0) &lt; time.time():\n                del self._cache[key]\n                return None\n\n            # Move to end (LRU behavior)\n            self._cache.move_to_end(key)\n            return data.get('value')\n\n        except Exception:\n            return None\n\n    async def set(\n        self, namespace: str, params: dict, value: dict, ttl_seconds: int = 300\n    ) -&gt; None:\n        \"\"\"Cache value with TTL (default 5 minutes).\"\"\"\n        try:\n            self._cleanup_expired()\n            self._evict_if_full()\n\n            key = self._make_key(namespace, params)\n            expires_at = time.time() + ttl_seconds\n\n            self._cache[key] = {\n                'value': value,\n                'expires_at': expires_at,\n                'created_at': time.time()\n            }\n\n            # Move to end (LRU behavior)\n            self._cache.move_to_end(key)\n\n        except Exception:\n            pass  # Fail silently on cache errors\n\n    async def close(self) -&gt; None:\n        \"\"\"Clean up cache.\"\"\"\n        self._cache.clear()\n</code></pre>"},{"location":"api/cache/#core.cache.InMemoryCache.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Clean up cache.</p> Source code in <code>core/cache.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Clean up cache.\"\"\"\n    self._cache.clear()\n</code></pre>"},{"location":"api/cache/#core.cache.InMemoryCache.get","title":"<code>get(namespace, params)</code>  <code>async</code>","text":"<p>Get cached value or None if not found/expired.</p> Source code in <code>core/cache.py</code> <pre><code>async def get(self, namespace: str, params: dict) -&gt; Optional[dict]:\n    \"\"\"Get cached value or None if not found/expired.\"\"\"\n    try:\n        self._cleanup_expired()\n        key = self._make_key(namespace, params)\n        data = self._cache.get(key)\n\n        if data is None:\n            return None\n\n        # Check if expired\n        if data.get('expires_at', 0) &lt; time.time():\n            del self._cache[key]\n            return None\n\n        # Move to end (LRU behavior)\n        self._cache.move_to_end(key)\n        return data.get('value')\n\n    except Exception:\n        return None\n</code></pre>"},{"location":"api/cache/#core.cache.InMemoryCache.set","title":"<code>set(namespace, params, value, ttl_seconds=300)</code>  <code>async</code>","text":"<p>Cache value with TTL (default 5 minutes).</p> Source code in <code>core/cache.py</code> <pre><code>async def set(\n    self, namespace: str, params: dict, value: dict, ttl_seconds: int = 300\n) -&gt; None:\n    \"\"\"Cache value with TTL (default 5 minutes).\"\"\"\n    try:\n        self._cleanup_expired()\n        self._evict_if_full()\n\n        key = self._make_key(namespace, params)\n        expires_at = time.time() + ttl_seconds\n\n        self._cache[key] = {\n            'value': value,\n            'expires_at': expires_at,\n            'created_at': time.time()\n        }\n\n        # Move to end (LRU behavior)\n        self._cache.move_to_end(key)\n\n    except Exception:\n        pass  # Fail silently on cache errors\n</code></pre>"},{"location":"api/cache/#core.cache.RedisCache","title":"<code>RedisCache</code>","text":"<p>Async Redis wrapper for caching API responses with TTL.</p> Source code in <code>core/cache.py</code> <pre><code>class RedisCache:\n    \"\"\"Async Redis wrapper for caching API responses with TTL.\"\"\"\n\n    def __init__(self, redis_url: Optional[str] = None):\n        url = redis_url or os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n        self._client = redis.from_url(url, decode_responses=True)\n        self._available = True\n\n    async def close(self) -&gt; None:\n        await self._client.aclose()\n\n    def _make_key(self, namespace: str, params: dict) -&gt; str:\n        \"\"\"Create cache key from namespace and sorted params.\"\"\"\n        param_str = json.dumps(params, sort_keys=True)\n        hash_suffix = hashlib.md5(param_str.encode()).hexdigest()[:8]\n        return f\"{namespace}:{hash_suffix}\"\n\n    async def get(self, namespace: str, params: dict) -&gt; Optional[dict]:\n        \"\"\"Get cached value or None if not found/expired.\"\"\"\n        if not self._available:\n            return None\n\n        try:\n            key = self._make_key(namespace, params)\n            cached = await self._client.get(key)\n            return json.loads(cached) if cached else None\n        except Exception:\n            self._available = False\n            return None\n\n    async def set(\n        self, namespace: str, params: dict, value: dict, ttl_seconds: int = 300\n    ) -&gt; None:\n        \"\"\"Cache value with TTL (default 5 minutes).\"\"\"\n        if not self._available:\n            return\n\n        try:\n            key = self._make_key(namespace, params)\n            await self._client.setex(key, ttl_seconds, json.dumps(value))\n        except Exception:\n            self._available = False\n</code></pre>"},{"location":"api/cache/#core.cache.RedisCache.get","title":"<code>get(namespace, params)</code>  <code>async</code>","text":"<p>Get cached value or None if not found/expired.</p> Source code in <code>core/cache.py</code> <pre><code>async def get(self, namespace: str, params: dict) -&gt; Optional[dict]:\n    \"\"\"Get cached value or None if not found/expired.\"\"\"\n    if not self._available:\n        return None\n\n    try:\n        key = self._make_key(namespace, params)\n        cached = await self._client.get(key)\n        return json.loads(cached) if cached else None\n    except Exception:\n        self._available = False\n        return None\n</code></pre>"},{"location":"api/cache/#core.cache.RedisCache.set","title":"<code>set(namespace, params, value, ttl_seconds=300)</code>  <code>async</code>","text":"<p>Cache value with TTL (default 5 minutes).</p> Source code in <code>core/cache.py</code> <pre><code>async def set(\n    self, namespace: str, params: dict, value: dict, ttl_seconds: int = 300\n) -&gt; None:\n    \"\"\"Cache value with TTL (default 5 minutes).\"\"\"\n    if not self._available:\n        return\n\n    try:\n        key = self._make_key(namespace, params)\n        await self._client.setex(key, ttl_seconds, json.dumps(value))\n    except Exception:\n        self._available = False\n</code></pre>"},{"location":"api/cache/#core.cache.cached_request","title":"<code>cached_request(namespace, params, fetch_func, ttl_seconds=300)</code>  <code>async</code>","text":"<p>Helper for cache-or-fetch pattern with automatic fallback.</p> Source code in <code>core/cache.py</code> <pre><code>async def cached_request(\n    namespace: str,\n    params: dict,\n    fetch_func,\n    ttl_seconds: int = 300,\n) -&gt; dict:\n    \"\"\"Helper for cache-or-fetch pattern with automatic fallback.\"\"\"\n    cache = get_cache()\n\n    # Try cache first\n    cached = await cache.get(namespace, params)\n    if cached is not None:\n        return cached\n\n    # Cache miss - fetch fresh data\n    result = await fetch_func()\n    await cache.set(namespace, params, result, ttl_seconds)\n    return result\n</code></pre>"},{"location":"api/cache/#core.cache.get_cache","title":"<code>get_cache()</code>","text":"<p>Return the global cache instance with automatic fallback.</p> Source code in <code>core/cache.py</code> <pre><code>def get_cache() -&gt; HybridCache:\n    \"\"\"Return the global cache instance with automatic fallback.\"\"\"\n    global _cache\n    if _cache is None:\n        # Check if Redis should be used\n        use_redis = os.getenv(\"USE_REDIS\", \"true\").lower() == \"true\"\n        redis_url = os.getenv(\"REDIS_URL\")\n\n        # If no Redis URL provided, use in-memory only\n        if not redis_url:\n            use_redis = False\n\n        _cache = HybridCache(redis_url, use_redis)\n    return _cache\n</code></pre>"},{"location":"api/data_sources/","title":"Data Sources","text":""},{"location":"api/data_sources/#core.data_sources.CoinMarketCapAPIError","title":"<code>CoinMarketCapAPIError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when CoinMarketCap API responds with error.</p> Source code in <code>core/data_sources.py</code> <pre><code>class CoinMarketCapAPIError(Exception):\n    \"\"\"Raised when CoinMarketCap API responds with error.\"\"\"\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.CoinMarketCapClient","title":"<code>CoinMarketCapClient</code>","text":"<p>Simple async wrapper for CoinMarketCap quotes endpoint.</p> <p>Docs: https://coinmarketcap.com/api/documentation/v1/</p> Source code in <code>core/data_sources.py</code> <pre><code>class CoinMarketCapClient:\n    \"\"\"Simple async wrapper for CoinMarketCap quotes endpoint.\n\n    Docs: https://coinmarketcap.com/api/documentation/v1/\n    \"\"\"\n\n    _BASE_URL = \"https://pro-api.coinmarketcap.com/v1\"\n\n    def __init__(self, api_key: Optional[str] = None, *, timeout: float = 10.0):\n        self.api_key = api_key or os.getenv(\"CMC_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"CMC API key not provided via arg or CMC_API_KEY env var.\")\n        self._client = httpx.AsyncClient(\n            timeout=timeout,\n            headers={\"X-CMC_PRO_API_KEY\": self.api_key},\n        )\n\n    async def close(self) -&gt; None:\n        await self._client.aclose()\n\n    async def token_quote(self, symbol: str) -&gt; Dict[str, float]:\n        \"\"\"Return market-cap, 24h volume (USD), and price for a token symbol.\"\"\"\n        cache_params = {\"symbol\": symbol.upper()}\n\n        async def fetch_quote():\n            url = f\"{self._BASE_URL}/cryptocurrency/quotes/latest\"\n            params = {\"symbol\": symbol.upper(), \"convert\": \"USD\"}\n            r = await request_with_retries(self._client, \"GET\", url, params=params)\n            if r.status_code != 200:\n                raise CoinMarketCapAPIError(f\"CMC {r.status_code}: {r.text}\")\n            data = r.json()\n            info = data[\"data\"].get(symbol.upper())\n            if not info:\n                raise CoinMarketCapAPIError(\"Symbol not found in CMC response\")\n            quote = info[\"quote\"][\"USD\"]\n            return {\n                \"market_cap_usd\": float(quote.get(\"market_cap\", 0)),\n                \"volume_24h_usd\": float(quote.get(\"volume_24h\", 0)),\n                \"price_usd\": float(quote.get(\"price\", 0)),\n            }\n\n        return await cached_request(\n            \"cmc_quote\", cache_params, fetch_quote, ttl_seconds=300\n        )\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.CoinMarketCapClient.token_quote","title":"<code>token_quote(symbol)</code>  <code>async</code>","text":"<p>Return market-cap, 24h volume (USD), and price for a token symbol.</p> Source code in <code>core/data_sources.py</code> <pre><code>async def token_quote(self, symbol: str) -&gt; Dict[str, float]:\n    \"\"\"Return market-cap, 24h volume (USD), and price for a token symbol.\"\"\"\n    cache_params = {\"symbol\": symbol.upper()}\n\n    async def fetch_quote():\n        url = f\"{self._BASE_URL}/cryptocurrency/quotes/latest\"\n        params = {\"symbol\": symbol.upper(), \"convert\": \"USD\"}\n        r = await request_with_retries(self._client, \"GET\", url, params=params)\n        if r.status_code != 200:\n            raise CoinMarketCapAPIError(f\"CMC {r.status_code}: {r.text}\")\n        data = r.json()\n        info = data[\"data\"].get(symbol.upper())\n        if not info:\n            raise CoinMarketCapAPIError(\"Symbol not found in CMC response\")\n        quote = info[\"quote\"][\"USD\"]\n        return {\n            \"market_cap_usd\": float(quote.get(\"market_cap\", 0)),\n            \"volume_24h_usd\": float(quote.get(\"volume_24h\", 0)),\n            \"price_usd\": float(quote.get(\"price\", 0)),\n        }\n\n    return await cached_request(\n        \"cmc_quote\", cache_params, fetch_quote, ttl_seconds=300\n    )\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.NansenAPIError","title":"<code>NansenAPIError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when Nansen API returns an error response.</p> Source code in <code>core/data_sources.py</code> <pre><code>class NansenAPIError(Exception):\n    \"\"\"Raised when Nansen API returns an error response.\"\"\"\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.NansenClient","title":"<code>NansenClient</code>","text":"<p>Async wrapper around the Nansen v1 API.</p> <p>Currently used for Smart-Money net flows. Docs: https://docs.nansen.ai/ \u203a API \u203a Smart Money \u203a Flows</p> Source code in <code>core/data_sources.py</code> <pre><code>class NansenClient:\n    \"\"\"Async wrapper around the Nansen v1 API.\n\n    Currently used for Smart-Money net flows.\n    Docs: https://docs.nansen.ai/ \u203a API \u203a Smart Money \u203a Flows\n    \"\"\"\n\n    _BASE_URL = \"https://api.nansen.ai/v1\"\n\n    def __init__(self, api_key: Optional[str] = None, *, timeout: float = 10.0):\n        self.api_key = api_key or os.getenv(\"NANSEN_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\n                \"Nansen API key not provided via arg or NANSEN_API_KEY env var.\"\n            )\n        self._client = httpx.AsyncClient(\n            timeout=timeout,\n            headers={\"x-api-key\": self.api_key},\n        )\n\n    async def close(self) -&gt; None:\n        await self._client.aclose()\n\n    # --------------------------- Nansen API ---------------------------\n    async def smart_money_netflow(\n        self,\n        token_address: str,\n        *,\n        chain_id: int = 1,\n        window: str = \"24h\",\n    ) -&gt; Dict[str, float]:\n        \"\"\"Fetch smart-money inflow/outflow data.\n\n        Parameters\n        ----------\n        token_address : str  Contract address (checksum or lowercase).\n        chain_id      : int  EVM chain id (1 = Ethereum, 56 = BSC\u2026). Defaults to 1.\n        window        : str  1h | 6h | 24h | 7d. Defaults to 24h.\n        \"\"\"\n        cache_params = {\n            \"address\": token_address,\n            \"chain_id\": chain_id,\n            \"window\": window,\n        }\n\n        async def fetch_flows():\n            url = f\"{self._BASE_URL}/smart-money/flows\"\n            params = {\n                \"address\": token_address,\n                \"chain_id\": chain_id,\n                \"window\": window,\n            }\n            r = await request_with_retries(self._client, \"GET\", url, params=params)\n            if r.status_code != 200:\n                raise NansenAPIError(f\"Nansen API {r.status_code}: {r.text}\")\n            data = r.json()\n            return {\n                \"inflow_usd\": float(data.get(\"inflow_usd\", 0)),\n                \"outflow_usd\": float(data.get(\"outflow_usd\", 0)),\n                \"netflow_usd\": float(\n                    data.get(\n                        \"netflow_usd\",\n                        data.get(\"inflow_usd\", 0) - data.get(\"outflow_usd\", 0),\n                    )\n                ),\n            }\n\n        return await cached_request(\n            \"nansen_flows\", cache_params, fetch_flows, ttl_seconds=300\n        )\n\n    async def netflow_score(\n        self, token_address: str, *, chain_id: int = 1, window: str = \"24h\"\n    ) -&gt; Dict[str, float]:\n        \"\"\"Compute normalized netflow score in range [-1, 1].\n\n        score = (inflow - outflow) / (inflow + outflow)\n        Returns dict with score and raw flows.\n        \"\"\"\n        flows = await self.smart_money_netflow(\n            token_address, chain_id=chain_id, window=window\n        )\n        inflow = flows[\"inflow_usd\"]\n        outflow = flows[\"outflow_usd\"]\n        netflow = flows[\"netflow_usd\"]\n        denom = inflow + outflow or 1.0\n        score = netflow / denom\n        return {\n            \"score\": round(score, 3),\n            \"inflow_usd\": inflow,\n            \"outflow_usd\": outflow,\n        }\n\n    # ----------------------- Token God Mode - Holders ----------------------\n    async def holder_count(self, token_address: str, *, chain_id: int = 1) -&gt; int:\n        \"\"\"Return total number of holders for a token.\n\n        Docs path: /v1/token/holders\n        Example response: {\"address\": \"0x...\", \"chain_id\": 1, \"holder_count\": 12345}\n        \"\"\"\n        cache_params = {\"address\": token_address, \"chain_id\": chain_id}\n\n        async def fetch_holders():\n            url = f\"{self._BASE_URL}/token/holders\"\n            params = {\"address\": token_address, \"chain_id\": chain_id}\n            r = await request_with_retries(self._client, \"GET\", url, params=params)\n            if r.status_code != 200:\n                raise NansenAPIError(f\"Nansen API {r.status_code}: {r.text}\")\n            data = r.json()\n            return {\"holder_count\": int(data.get(\"holder_count\", 0))}\n\n        result = await cached_request(\n            \"nansen_holders\", cache_params, fetch_holders, ttl_seconds=300\n        )\n        return result[\"holder_count\"]\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.NansenClient.holder_count","title":"<code>holder_count(token_address, *, chain_id=1)</code>  <code>async</code>","text":"<p>Return total number of holders for a token.</p> <p>Docs path: /v1/token/holders Example response: {\"address\": \"0x...\", \"chain_id\": 1, \"holder_count\": 12345}</p> Source code in <code>core/data_sources.py</code> <pre><code>async def holder_count(self, token_address: str, *, chain_id: int = 1) -&gt; int:\n    \"\"\"Return total number of holders for a token.\n\n    Docs path: /v1/token/holders\n    Example response: {\"address\": \"0x...\", \"chain_id\": 1, \"holder_count\": 12345}\n    \"\"\"\n    cache_params = {\"address\": token_address, \"chain_id\": chain_id}\n\n    async def fetch_holders():\n        url = f\"{self._BASE_URL}/token/holders\"\n        params = {\"address\": token_address, \"chain_id\": chain_id}\n        r = await request_with_retries(self._client, \"GET\", url, params=params)\n        if r.status_code != 200:\n            raise NansenAPIError(f\"Nansen API {r.status_code}: {r.text}\")\n        data = r.json()\n        return {\"holder_count\": int(data.get(\"holder_count\", 0))}\n\n    result = await cached_request(\n        \"nansen_holders\", cache_params, fetch_holders, ttl_seconds=300\n    )\n    return result[\"holder_count\"]\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.NansenClient.netflow_score","title":"<code>netflow_score(token_address, *, chain_id=1, window='24h')</code>  <code>async</code>","text":"<p>Compute normalized netflow score in range [-1, 1].</p> <p>score = (inflow - outflow) / (inflow + outflow) Returns dict with score and raw flows.</p> Source code in <code>core/data_sources.py</code> <pre><code>async def netflow_score(\n    self, token_address: str, *, chain_id: int = 1, window: str = \"24h\"\n) -&gt; Dict[str, float]:\n    \"\"\"Compute normalized netflow score in range [-1, 1].\n\n    score = (inflow - outflow) / (inflow + outflow)\n    Returns dict with score and raw flows.\n    \"\"\"\n    flows = await self.smart_money_netflow(\n        token_address, chain_id=chain_id, window=window\n    )\n    inflow = flows[\"inflow_usd\"]\n    outflow = flows[\"outflow_usd\"]\n    netflow = flows[\"netflow_usd\"]\n    denom = inflow + outflow or 1.0\n    score = netflow / denom\n    return {\n        \"score\": round(score, 3),\n        \"inflow_usd\": inflow,\n        \"outflow_usd\": outflow,\n    }\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.NansenClient.smart_money_netflow","title":"<code>smart_money_netflow(token_address, *, chain_id=1, window='24h')</code>  <code>async</code>","text":"<p>Fetch smart-money inflow/outflow data.</p>"},{"location":"api/data_sources/#core.data_sources.NansenClient.smart_money_netflow--parameters","title":"Parameters","text":"<p>token_address : str  Contract address (checksum or lowercase). chain_id      : int  EVM chain id (1 = Ethereum, 56 = BSC\u2026). Defaults to 1. window        : str  1h | 6h | 24h | 7d. Defaults to 24h.</p> Source code in <code>core/data_sources.py</code> <pre><code>async def smart_money_netflow(\n    self,\n    token_address: str,\n    *,\n    chain_id: int = 1,\n    window: str = \"24h\",\n) -&gt; Dict[str, float]:\n    \"\"\"Fetch smart-money inflow/outflow data.\n\n    Parameters\n    ----------\n    token_address : str  Contract address (checksum or lowercase).\n    chain_id      : int  EVM chain id (1 = Ethereum, 56 = BSC\u2026). Defaults to 1.\n    window        : str  1h | 6h | 24h | 7d. Defaults to 24h.\n    \"\"\"\n    cache_params = {\n        \"address\": token_address,\n        \"chain_id\": chain_id,\n        \"window\": window,\n    }\n\n    async def fetch_flows():\n        url = f\"{self._BASE_URL}/smart-money/flows\"\n        params = {\n            \"address\": token_address,\n            \"chain_id\": chain_id,\n            \"window\": window,\n        }\n        r = await request_with_retries(self._client, \"GET\", url, params=params)\n        if r.status_code != 200:\n            raise NansenAPIError(f\"Nansen API {r.status_code}: {r.text}\")\n        data = r.json()\n        return {\n            \"inflow_usd\": float(data.get(\"inflow_usd\", 0)),\n            \"outflow_usd\": float(data.get(\"outflow_usd\", 0)),\n            \"netflow_usd\": float(\n                data.get(\n                    \"netflow_usd\",\n                    data.get(\"inflow_usd\", 0) - data.get(\"outflow_usd\", 0),\n                )\n            ),\n        }\n\n    return await cached_request(\n        \"nansen_flows\", cache_params, fetch_flows, ttl_seconds=300\n    )\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.TwitterAPIError","title":"<code>TwitterAPIError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when Twitter API returns a non-success status.</p> Source code in <code>core/data_sources.py</code> <pre><code>class TwitterAPIError(Exception):\n    \"\"\"Raised when Twitter API returns a non-success status.\"\"\"\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.TwitterClient","title":"<code>TwitterClient</code>","text":"<p>Async wrapper around the Twitter v2 API for recent search + sentiment scoring.</p> Source code in <code>core/data_sources.py</code> <pre><code>class TwitterClient:\n    \"\"\"Async wrapper around the Twitter v2 API for recent search + sentiment scoring.\"\"\"\n\n    _BASE_URL = \"https://api.twitter.com/2\"\n\n    def __init__(self, bearer_token: Optional[str] = None, *, timeout: float = 10.0):\n        self.bearer_token = bearer_token or os.getenv(\"TWITTER_BEARER_TOKEN\")\n        if not self.bearer_token:\n            raise ValueError(\n                \"Twitter bearer token not provided via arg or env var.\"\n            )\n        self._client = httpx.AsyncClient(\n            timeout=timeout,\n            headers={\"Authorization\": f\"Bearer {self.bearer_token}\"},\n        )\n        self._sentiment = SentimentIntensityAnalyzer()\n\n    async def close(self) -&gt; None:\n        await self._client.aclose()\n\n    # --------------------------- Twitter API ---------------------------\n    async def search_recent_tweets(\n        self, query: str, *, max_results: int = 50\n    ) -&gt; List[Tweet]:\n        \"\"\"Return recent tweets matching a query.\n\n        Docs: https://developer.twitter.com/en/docs/twitter-api/tweets/search/\n        \"\"\"\n        cache_params = {\"query\": query, \"max_results\": max_results}\n\n        async def fetch_tweets():\n            url = f\"{self._BASE_URL}/tweets/search/recent\"\n            params = {\n                \"query\": query,\n                \"max_results\": min(max_results, 100),\n                \"tweet.fields\": \"public_metrics\",\n            }\n            r = await request_with_retries(self._client, \"GET\", url, params=params)\n            if r.status_code != 200:\n                raise TwitterAPIError(f\"Twitter API {r.status_code}: {r.text}\")\n            payload = r.json()\n            tweets_data = []\n            for item in payload.get(\"data\", []):\n                metrics = item.get(\"public_metrics\", {})\n                tweets_data.append(\n                    {\n                        \"id\": item[\"id\"],\n                        \"text\": item[\"text\"],\n                        \"like_count\": metrics.get(\"like_count\", 0),\n                        \"retweet_count\": metrics.get(\"retweet_count\", 0),\n                        \"reply_count\": metrics.get(\"reply_count\", 0),\n                    }\n                )\n            return {\"tweets\": tweets_data}\n\n        result = await cached_request(\n            \"twitter_search\", cache_params, fetch_tweets, ttl_seconds=300\n        )\n        tweets = []\n        for item in result[\"tweets\"]:\n            tweets.append(Tweet(**item))\n        return tweets\n\n    # ------------------------ Sentiment Utilities ----------------------\n    def _score_text(self, text: str) -&gt; float:\n        \"\"\"Return compound sentiment score in range [-1, 1].\"\"\"\n        return self._sentiment.polarity_scores(text)[\"compound\"]\n\n    def _engagement_weight(self, tweet: Tweet) -&gt; int:\n        return (\n            tweet.like_count + tweet.retweet_count + tweet.reply_count + 1\n        )  # +1 to avoid 0 weight\n\n    # --------------------- Public High-level Helper --------------------\n    async def sentiment_for_token(self, token_symbol: str, *, limit: int = 50) -&gt; dict:\n        \"\"\"Compute weighted sentiment score for a given token symbol (e.g., ABC).\n\n        Returns dict with keys: score (float), tweet_count (int).\n        \"\"\"\n        query = f\"${token_symbol} lang:en -is:retweet\"\n        tweets = await self.search_recent_tweets(query, max_results=limit)\n        if not tweets:\n            return {\"score\": 0.0, \"tweet_count\": 0}\n\n        scores = [self._score_text(t.text) for t in tweets]\n        weights = [self._engagement_weight(t) for t in tweets]\n        weighted_scores = [s * w for s, w in zip(scores, weights)]\n        final = sum(weighted_scores) / sum(weights)\n        return {\"score\": round(final, 3), \"tweet_count\": len(tweets)}\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.TwitterClient.search_recent_tweets","title":"<code>search_recent_tweets(query, *, max_results=50)</code>  <code>async</code>","text":"<p>Return recent tweets matching a query.</p> <p>Docs: https://developer.twitter.com/en/docs/twitter-api/tweets/search/</p> Source code in <code>core/data_sources.py</code> <pre><code>async def search_recent_tweets(\n    self, query: str, *, max_results: int = 50\n) -&gt; List[Tweet]:\n    \"\"\"Return recent tweets matching a query.\n\n    Docs: https://developer.twitter.com/en/docs/twitter-api/tweets/search/\n    \"\"\"\n    cache_params = {\"query\": query, \"max_results\": max_results}\n\n    async def fetch_tweets():\n        url = f\"{self._BASE_URL}/tweets/search/recent\"\n        params = {\n            \"query\": query,\n            \"max_results\": min(max_results, 100),\n            \"tweet.fields\": \"public_metrics\",\n        }\n        r = await request_with_retries(self._client, \"GET\", url, params=params)\n        if r.status_code != 200:\n            raise TwitterAPIError(f\"Twitter API {r.status_code}: {r.text}\")\n        payload = r.json()\n        tweets_data = []\n        for item in payload.get(\"data\", []):\n            metrics = item.get(\"public_metrics\", {})\n            tweets_data.append(\n                {\n                    \"id\": item[\"id\"],\n                    \"text\": item[\"text\"],\n                    \"like_count\": metrics.get(\"like_count\", 0),\n                    \"retweet_count\": metrics.get(\"retweet_count\", 0),\n                    \"reply_count\": metrics.get(\"reply_count\", 0),\n                }\n            )\n        return {\"tweets\": tweets_data}\n\n    result = await cached_request(\n        \"twitter_search\", cache_params, fetch_tweets, ttl_seconds=300\n    )\n    tweets = []\n    for item in result[\"tweets\"]:\n        tweets.append(Tweet(**item))\n    return tweets\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.TwitterClient.sentiment_for_token","title":"<code>sentiment_for_token(token_symbol, *, limit=50)</code>  <code>async</code>","text":"<p>Compute weighted sentiment score for a given token symbol (e.g., ABC).</p> <p>Returns dict with keys: score (float), tweet_count (int).</p> Source code in <code>core/data_sources.py</code> <pre><code>async def sentiment_for_token(self, token_symbol: str, *, limit: int = 50) -&gt; dict:\n    \"\"\"Compute weighted sentiment score for a given token symbol (e.g., ABC).\n\n    Returns dict with keys: score (float), tweet_count (int).\n    \"\"\"\n    query = f\"${token_symbol} lang:en -is:retweet\"\n    tweets = await self.search_recent_tweets(query, max_results=limit)\n    if not tweets:\n        return {\"score\": 0.0, \"tweet_count\": 0}\n\n    scores = [self._score_text(t.text) for t in tweets]\n    weights = [self._engagement_weight(t) for t in tweets]\n    weighted_scores = [s * w for s, w in zip(scores, weights)]\n    final = sum(weighted_scores) / sum(weights)\n    return {\"score\": round(final, 3), \"tweet_count\": len(tweets)}\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.get_nansen_netflow_score","title":"<code>get_nansen_netflow_score(token_address, *, chain_id=1, api_key=None)</code>  <code>async</code>","text":"<p>Convenience helper for one-shot netflow score fetch.</p> Source code in <code>core/data_sources.py</code> <pre><code>async def get_nansen_netflow_score(\n    token_address: str, *, chain_id: int = 1, api_key: Optional[str] = None\n) -&gt; Dict[str, float]:\n    \"\"\"Convenience helper for one-shot netflow score fetch.\"\"\"\n    client = NansenClient(api_key)\n    try:\n        return await client.netflow_score(token_address, chain_id=chain_id)\n    finally:\n        await client.close()\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.get_token_holder_count","title":"<code>get_token_holder_count(token_address, *, chain_id=1, api_key=None)</code>  <code>async</code>","text":"<p>Convenience helper to fetch holder count via Nansen Token God Mode.</p> Source code in <code>core/data_sources.py</code> <pre><code>async def get_token_holder_count(\n    token_address: str, *, chain_id: int = 1, api_key: Optional[str] = None\n) -&gt; int:\n    \"\"\"Convenience helper to fetch holder count via Nansen Token God Mode.\"\"\"\n    client = NansenClient(api_key)\n    try:\n        return await client.holder_count(token_address, chain_id=chain_id)\n    finally:\n        await client.close()\n</code></pre>"},{"location":"api/data_sources/#core.data_sources.get_token_sentiment","title":"<code>get_token_sentiment(token_symbol, bearer_token=None)</code>  <code>async</code>","text":"<p>Convenience function to fetch weighted Twitter sentiment for a token.</p> Source code in <code>core/data_sources.py</code> <pre><code>async def get_token_sentiment(\n    token_symbol: str, bearer_token: Optional[str] = None\n) -&gt; dict:\n    \"\"\"Convenience function to fetch weighted Twitter sentiment for a token.\"\"\"\n    client = TwitterClient(bearer_token)\n    try:\n        return await client.sentiment_for_token(token_symbol)\n    finally:\n        await client.close()\n</code></pre>"},{"location":"api/http_utils/","title":"HTTP Utils","text":"<p>HTTP Utilities Module</p> <p>Provides robust HTTP request functionality with automatic retry logic, exponential backoff, and jitter for handling transient network issues.</p> <p>Features: - Exponential backoff with jitter - Retry on server errors and rate limiting - Configurable retry attempts and backoff factor - Thread-safe async operations</p>"},{"location":"api/http_utils/#core.http_utils.request_with_retries","title":"<code>request_with_retries(client, method, url, *, params=None, retries=3, backoff_factor=0.5)</code>  <code>async</code>","text":"<p>Perform an HTTP request with exponential backoff and automatic retries.</p> <p>This function implements a robust HTTP request pattern that automatically retries on transient failures, network errors, and retryable status codes. It uses exponential backoff with jitter to prevent thundering herd problems.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>AsyncClient</code> <p>The httpx.AsyncClient instance to use for requests</p> required <code>method</code> <code>str</code> <p>HTTP method (GET, POST, etc.)</p> required <code>url</code> <code>str</code> <p>Target URL for the request</p> required <code>params</code> <code>Optional[dict]</code> <p>Optional query parameters to include in the request</p> <code>None</code> <code>retries</code> <code>int</code> <p>Maximum number of retry attempts (default: 3)</p> <code>3</code> <code>backoff_factor</code> <code>float</code> <p>Base delay for exponential backoff in seconds (default: 0.5)</p> <code>0.5</code> <p>Returns:</p> Type Description <code>Response</code> <p>httpx.Response: The successful HTTP response</p> <p>Raises:</p> Type Description <code>RequestError</code> <p>If the request fails after all retry attempts</p> <code>TimeoutException</code> <p>If the request times out after all retry attempts</p> <code>HTTPStatusError</code> <p>If a non-retryable status code is received</p> Example <p>client = httpx.AsyncClient() response = await request_with_retries( ...     client, \"GET\", \"https://api.example.com/data\", ...     params={\"key\": \"value\"}, retries=5 ... )</p> Source code in <code>core/http_utils.py</code> <pre><code>async def request_with_retries(\n    client: httpx.AsyncClient,\n    method: str,\n    url: str,\n    *,\n    params: Optional[dict] = None,\n    retries: int = 3,\n    backoff_factor: float = 0.5,\n) -&gt; httpx.Response:\n    \"\"\"Perform an HTTP request with exponential backoff and automatic retries.\n\n    This function implements a robust HTTP request pattern that automatically\n    retries on transient failures, network errors, and retryable status codes.\n    It uses exponential backoff with jitter to prevent thundering herd problems.\n\n    Args:\n        client: The httpx.AsyncClient instance to use for requests\n        method: HTTP method (GET, POST, etc.)\n        url: Target URL for the request\n        params: Optional query parameters to include in the request\n        retries: Maximum number of retry attempts (default: 3)\n        backoff_factor: Base delay for exponential backoff in seconds (default: 0.5)\n\n    Returns:\n        httpx.Response: The successful HTTP response\n\n    Raises:\n        httpx.RequestError: If the request fails after all retry attempts\n        httpx.TimeoutException: If the request times out after all retry attempts\n        httpx.HTTPStatusError: If a non-retryable status code is received\n\n    Example:\n        &gt;&gt;&gt; client = httpx.AsyncClient()\n        &gt;&gt;&gt; response = await request_with_retries(\n        ...     client, \"GET\", \"https://api.example.com/data\",\n        ...     params={\"key\": \"value\"}, retries=5\n        ... )\n    \"\"\"\n    delay = backoff_factor\n    for attempt in range(retries):\n        try:\n            resp = await client.request(method, url, params=params)\n            if resp.status_code in _RETRY_STATUS and attempt &lt; retries - 1:\n                raise httpx.HTTPStatusError(\n                    \"retryable status\", request=resp.request, response=resp\n                )\n            return resp\n        except (httpx.RequestError, httpx.TimeoutException, httpx.HTTPStatusError):\n            if attempt == retries - 1:\n                raise\n            jitter = random.uniform(0, delay)\n            await asyncio.sleep(delay + jitter)\n            delay *= 2\n    # Should never reach here\n    raise RuntimeError(\"Exceeded retry attempts\")\n</code></pre>"},{"location":"api/rate_limiter/","title":"Rate Limiter","text":"<p>In-memory rate limiter with sliding window algorithm.</p> <p>Provides rate limiting functionality without requiring Redis, suitable for MVP deployment with zero infrastructure costs.</p>"},{"location":"api/rate_limiter/#core.rate_limiter.InMemoryRateLimiter","title":"<code>InMemoryRateLimiter</code>","text":"<p>In-memory rate limiter using sliding window algorithm.</p> <p>Features: - Sliding window rate limiting - Automatic cleanup of expired entries - Thread-safe operations - Memory-efficient storage - No external dependencies</p> Source code in <code>core/rate_limiter.py</code> <pre><code>class InMemoryRateLimiter:\n    \"\"\"\n    In-memory rate limiter using sliding window algorithm.\n\n    Features:\n    - Sliding window rate limiting\n    - Automatic cleanup of expired entries\n    - Thread-safe operations\n    - Memory-efficient storage\n    - No external dependencies\n    \"\"\"\n\n    def __init__(self, config: Optional[RateLimitConfig] = None):\n        self.config = config or RateLimitConfig()\n        self._user_requests: Dict[int, List[float]] = defaultdict(list)\n        self._global_requests: List[float] = []\n        self._lock = threading.RLock()\n        self._last_cleanup = time.time()\n\n    def _cleanup_expired_entries(self) -&gt; None:\n        \"\"\"Remove expired request timestamps to prevent memory bloat.\"\"\"\n        current_time = time.time()\n        cutoff_time = current_time - self.config.window_seconds\n\n        # Clean up user requests\n        expired_users = []\n        for user_id, requests in self._user_requests.items():\n            # Keep only requests within the window\n            self._user_requests[user_id] = [\n                req_time for req_time in requests\n                if req_time &gt; cutoff_time\n            ]\n            # Remove user if no requests remain\n            if not self._user_requests[user_id]:\n                expired_users.append(user_id)\n\n        for user_id in expired_users:\n            del self._user_requests[user_id]\n\n        # Clean up global requests\n        self._global_requests = [\n            req_time for req_time in self._global_requests\n            if req_time &gt; cutoff_time\n        ]\n\n        self._last_cleanup = current_time\n\n    def _should_cleanup(self) -&gt; bool:\n        \"\"\"Check if cleanup is needed.\"\"\"\n        return time.time() - self._last_cleanup &gt; self.config.cleanup_interval\n\n    def is_allowed(self, user_id: int) -&gt; Tuple[bool, Dict[str, Any]]:\n        \"\"\"\n        Check if a user is allowed to make a request.\n\n        Args:\n            user_id: Telegram user ID\n\n        Returns:\n            Tuple of (is_allowed, rate_limit_info)\n        \"\"\"\n        with self._lock:\n            if self._should_cleanup():\n                self._cleanup_expired_entries()\n\n            current_time = time.time()\n            cutoff_time = current_time - self.config.window_seconds\n\n            # Get user's recent requests\n            user_requests = self._user_requests[user_id]\n\n            # Remove expired requests\n            recent_requests = [\n                req_time for req_time in user_requests\n                if req_time &gt; cutoff_time\n            ]\n\n            # Check if user has exceeded the limit\n            is_allowed = len(recent_requests) &lt; self.config.max_requests\n\n            # Calculate rate limit info\n            remaining_requests = max(0, self.config.max_requests - len(recent_requests))\n            reset_time = None\n\n            if recent_requests:\n                # Calculate when the oldest request will expire\n                oldest_request = min(recent_requests)\n                reset_time = oldest_request + self.config.window_seconds\n\n            rate_limit_info = {\n                'is_allowed': is_allowed,\n                'remaining_requests': remaining_requests,\n                'max_requests': self.config.max_requests,\n                'window_seconds': self.config.window_seconds,\n                'reset_time': reset_time,\n                'current_requests': len(recent_requests)\n            }\n\n            return is_allowed, rate_limit_info\n\n    def record_request(self, user_id: int) -&gt; None:\n        \"\"\"\n        Record a successful request for rate limiting.\n\n        Args:\n            user_id: Telegram user ID\n        \"\"\"\n        with self._lock:\n            current_time = time.time()\n            self._user_requests[user_id].append(current_time)\n            self._global_requests.append(current_time)\n\n    def get_user_stats(self, user_id: int) -&gt; Dict[str, Any]:\n        \"\"\"\n        Get rate limiting statistics for a specific user.\n\n        Args:\n            user_id: Telegram user ID\n\n        Returns:\n            Dictionary with user statistics\n        \"\"\"\n        with self._lock:\n            if self._should_cleanup():\n                self._cleanup_expired_entries()\n\n            current_time = time.time()\n            cutoff_time = current_time - self.config.window_seconds\n\n            user_requests = self._user_requests[user_id]\n            recent_requests = [\n                req_time for req_time in user_requests\n                if req_time &gt; cutoff_time\n            ]\n\n            return {\n                'user_id': user_id,\n                'total_requests': len(user_requests),\n                'recent_requests': len(recent_requests),\n                'max_requests': self.config.max_requests,\n                'remaining_requests': max(0, self.config.max_requests - len(recent_requests)),\n                'window_seconds': self.config.window_seconds,\n                'last_request': max(recent_requests) if recent_requests else None\n            }\n\n    def get_global_stats(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Get global rate limiting statistics.\n\n        Returns:\n            Dictionary with global statistics\n        \"\"\"\n        with self._lock:\n            if self._should_cleanup():\n                self._cleanup_expired_entries()\n\n            current_time = time.time()\n            cutoff_time = current_time - self.config.window_seconds\n\n            recent_global_requests = [\n                req_time for req_time in self._global_requests\n                if req_time &gt; cutoff_time\n            ]\n\n            return {\n                'total_users': len(self._user_requests),\n                'total_requests': len(self._global_requests),\n                'recent_requests': len(recent_global_requests),\n                'window_seconds': self.config.window_seconds,\n                'last_request': max(recent_global_requests) if recent_global_requests else None\n            }\n\n    def reset_user(self, user_id: int) -&gt; None:\n        \"\"\"\n        Reset rate limiting for a specific user.\n\n        Args:\n            user_id: Telegram user ID\n        \"\"\"\n        with self._lock:\n            if user_id in self._user_requests:\n                del self._user_requests[user_id]\n\n    def reset_all(self) -&gt; None:\n        \"\"\"Reset all rate limiting data.\"\"\"\n        with self._lock:\n            self._user_requests.clear()\n            self._global_requests.clear()\n            self._last_cleanup = time.time()\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.InMemoryRateLimiter.get_global_stats","title":"<code>get_global_stats()</code>","text":"<p>Get global rate limiting statistics.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with global statistics</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def get_global_stats(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get global rate limiting statistics.\n\n    Returns:\n        Dictionary with global statistics\n    \"\"\"\n    with self._lock:\n        if self._should_cleanup():\n            self._cleanup_expired_entries()\n\n        current_time = time.time()\n        cutoff_time = current_time - self.config.window_seconds\n\n        recent_global_requests = [\n            req_time for req_time in self._global_requests\n            if req_time &gt; cutoff_time\n        ]\n\n        return {\n            'total_users': len(self._user_requests),\n            'total_requests': len(self._global_requests),\n            'recent_requests': len(recent_global_requests),\n            'window_seconds': self.config.window_seconds,\n            'last_request': max(recent_global_requests) if recent_global_requests else None\n        }\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.InMemoryRateLimiter.get_user_stats","title":"<code>get_user_stats(user_id)</code>","text":"<p>Get rate limiting statistics for a specific user.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Telegram user ID</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with user statistics</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def get_user_stats(self, user_id: int) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get rate limiting statistics for a specific user.\n\n    Args:\n        user_id: Telegram user ID\n\n    Returns:\n        Dictionary with user statistics\n    \"\"\"\n    with self._lock:\n        if self._should_cleanup():\n            self._cleanup_expired_entries()\n\n        current_time = time.time()\n        cutoff_time = current_time - self.config.window_seconds\n\n        user_requests = self._user_requests[user_id]\n        recent_requests = [\n            req_time for req_time in user_requests\n            if req_time &gt; cutoff_time\n        ]\n\n        return {\n            'user_id': user_id,\n            'total_requests': len(user_requests),\n            'recent_requests': len(recent_requests),\n            'max_requests': self.config.max_requests,\n            'remaining_requests': max(0, self.config.max_requests - len(recent_requests)),\n            'window_seconds': self.config.window_seconds,\n            'last_request': max(recent_requests) if recent_requests else None\n        }\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.InMemoryRateLimiter.is_allowed","title":"<code>is_allowed(user_id)</code>","text":"<p>Check if a user is allowed to make a request.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Telegram user ID</p> required <p>Returns:</p> Type Description <code>Tuple[bool, Dict[str, Any]]</code> <p>Tuple of (is_allowed, rate_limit_info)</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def is_allowed(self, user_id: int) -&gt; Tuple[bool, Dict[str, Any]]:\n    \"\"\"\n    Check if a user is allowed to make a request.\n\n    Args:\n        user_id: Telegram user ID\n\n    Returns:\n        Tuple of (is_allowed, rate_limit_info)\n    \"\"\"\n    with self._lock:\n        if self._should_cleanup():\n            self._cleanup_expired_entries()\n\n        current_time = time.time()\n        cutoff_time = current_time - self.config.window_seconds\n\n        # Get user's recent requests\n        user_requests = self._user_requests[user_id]\n\n        # Remove expired requests\n        recent_requests = [\n            req_time for req_time in user_requests\n            if req_time &gt; cutoff_time\n        ]\n\n        # Check if user has exceeded the limit\n        is_allowed = len(recent_requests) &lt; self.config.max_requests\n\n        # Calculate rate limit info\n        remaining_requests = max(0, self.config.max_requests - len(recent_requests))\n        reset_time = None\n\n        if recent_requests:\n            # Calculate when the oldest request will expire\n            oldest_request = min(recent_requests)\n            reset_time = oldest_request + self.config.window_seconds\n\n        rate_limit_info = {\n            'is_allowed': is_allowed,\n            'remaining_requests': remaining_requests,\n            'max_requests': self.config.max_requests,\n            'window_seconds': self.config.window_seconds,\n            'reset_time': reset_time,\n            'current_requests': len(recent_requests)\n        }\n\n        return is_allowed, rate_limit_info\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.InMemoryRateLimiter.record_request","title":"<code>record_request(user_id)</code>","text":"<p>Record a successful request for rate limiting.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Telegram user ID</p> required Source code in <code>core/rate_limiter.py</code> <pre><code>def record_request(self, user_id: int) -&gt; None:\n    \"\"\"\n    Record a successful request for rate limiting.\n\n    Args:\n        user_id: Telegram user ID\n    \"\"\"\n    with self._lock:\n        current_time = time.time()\n        self._user_requests[user_id].append(current_time)\n        self._global_requests.append(current_time)\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.InMemoryRateLimiter.reset_all","title":"<code>reset_all()</code>","text":"<p>Reset all rate limiting data.</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def reset_all(self) -&gt; None:\n    \"\"\"Reset all rate limiting data.\"\"\"\n    with self._lock:\n        self._user_requests.clear()\n        self._global_requests.clear()\n        self._last_cleanup = time.time()\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.InMemoryRateLimiter.reset_user","title":"<code>reset_user(user_id)</code>","text":"<p>Reset rate limiting for a specific user.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Telegram user ID</p> required Source code in <code>core/rate_limiter.py</code> <pre><code>def reset_user(self, user_id: int) -&gt; None:\n    \"\"\"\n    Reset rate limiting for a specific user.\n\n    Args:\n        user_id: Telegram user ID\n    \"\"\"\n    with self._lock:\n        if user_id in self._user_requests:\n            del self._user_requests[user_id]\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.RateLimitConfig","title":"<code>RateLimitConfig</code>  <code>dataclass</code>","text":"<p>Configuration for rate limiting.</p> Source code in <code>core/rate_limiter.py</code> <pre><code>@dataclass\nclass RateLimitConfig:\n    \"\"\"Configuration for rate limiting.\"\"\"\n    max_requests: int = 2\n    window_seconds: int = 60\n    cleanup_interval: int = 300  # Clean up old entries every 5 minutes\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.check_rate_limit","title":"<code>check_rate_limit(user_id)</code>","text":"<p>Check if a user is within rate limits.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Telegram user ID</p> required <p>Returns:</p> Type Description <code>Tuple[bool, Dict[str, any]]</code> <p>Tuple of (is_allowed, rate_limit_info)</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def check_rate_limit(user_id: int) -&gt; Tuple[bool, Dict[str, any]]:\n    \"\"\"\n    Check if a user is within rate limits.\n\n    Args:\n        user_id: Telegram user ID\n\n    Returns:\n        Tuple of (is_allowed, rate_limit_info)\n    \"\"\"\n    return get_rate_limiter().is_allowed(user_id)\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.get_global_rate_limit_stats","title":"<code>get_global_rate_limit_stats()</code>","text":"<p>Get global rate limiting statistics.</p> <p>Returns:</p> Type Description <code>Dict[str, any]</code> <p>Dictionary with global statistics</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def get_global_rate_limit_stats() -&gt; Dict[str, any]:\n    \"\"\"\n    Get global rate limiting statistics.\n\n    Returns:\n        Dictionary with global statistics\n    \"\"\"\n    return get_rate_limiter().get_global_stats() \n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.get_rate_limiter","title":"<code>get_rate_limiter()</code>","text":"<p>Get the global rate limiter instance.</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def get_rate_limiter() -&gt; InMemoryRateLimiter:\n    \"\"\"Get the global rate limiter instance.\"\"\"\n    global _rate_limiter\n    if _rate_limiter is None:\n        _rate_limiter = InMemoryRateLimiter()\n    return _rate_limiter\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.get_user_rate_limit_stats","title":"<code>get_user_rate_limit_stats(user_id)</code>","text":"<p>Get rate limiting statistics for a user.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Telegram user ID</p> required <p>Returns:</p> Type Description <code>Dict[str, any]</code> <p>Dictionary with user statistics</p> Source code in <code>core/rate_limiter.py</code> <pre><code>def get_user_rate_limit_stats(user_id: int) -&gt; Dict[str, any]:\n    \"\"\"\n    Get rate limiting statistics for a user.\n\n    Args:\n        user_id: Telegram user ID\n\n    Returns:\n        Dictionary with user statistics\n    \"\"\"\n    return get_rate_limiter().get_user_stats(user_id)\n</code></pre>"},{"location":"api/rate_limiter/#core.rate_limiter.record_request","title":"<code>record_request(user_id)</code>","text":"<p>Record a successful request for rate limiting.</p> <p>Parameters:</p> Name Type Description Default <code>user_id</code> <code>int</code> <p>Telegram user ID</p> required Source code in <code>core/rate_limiter.py</code> <pre><code>def record_request(user_id: int) -&gt; None:\n    \"\"\"\n    Record a successful request for rate limiting.\n\n    Args:\n        user_id: Telegram user ID\n    \"\"\"\n    get_rate_limiter().record_request(user_id)\n</code></pre>"},{"location":"api/sentiment_engine/","title":"Sentiment Engine","text":"<p>Sentiment Analysis Engine</p> <p>Aggregates data from three pillars (Twitter, Nansen, Fundamentals) with proper  weighting (60/25/15) to compute Bullish/Neutral/Bearish signals with confidence scores.</p> <p>Based on PRD requirements: - Weight: 60% on-chain smart-money flows (Nansen), 25% Twitter sentiment, 15% fundamentals - Output: Bullish/Neutral/Bearish with confidence % and three-bullet rationale - Handle missing data by downgrading confidence proportionally</p>"},{"location":"api/sentiment_engine/#core.sentiment_engine.FundamentalsPillarData","title":"<code>FundamentalsPillarData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Token fundamentals pillar data (market cap, volume, price).</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>class FundamentalsPillarData(BaseModel):\n    \"\"\"Token fundamentals pillar data (market cap, volume, price).\"\"\"\n\n    market_cap_usd: float = Field(\n        ...,\n        gt=0,\n        description=\"Market capitalization in USD\"\n    )\n    volume_24h_usd: float = Field(\n        ...,\n        ge=0,\n        description=\"24-hour trading volume in USD\"\n    )\n    price_usd: float = Field(\n        ...,\n        gt=0,\n        description=\"Current token price in USD\"\n    )\n    volume_to_mcap_ratio: float = Field(\n        default=0.0,\n        ge=0.0,\n        description=\"Volume to market cap ratio (indicates liquidity)\"\n    )\n    data_quality: float = Field(\n        default=1.0,\n        ge=0.0,\n        le=1.0,\n        description=\"Data quality score (0=no data, 1=excellent data)\"\n    )\n\n    @validator('volume_to_mcap_ratio', always=True)\n    def calculate_volume_ratio(cls, v, values):\n        \"\"\"Calculate volume to market cap ratio.\"\"\"\n        volume = values.get('volume_24h_usd', 0)\n        mcap = values.get('market_cap_usd', 1)  # Avoid division by zero\n        return round(volume / mcap, 4)\n\n    @validator('data_quality', always=True) \n    def calculate_data_quality(cls, v, values):\n        \"\"\"Calculate data quality based on market cap size.\"\"\"\n        mcap = values.get('market_cap_usd', 0)\n\n        if mcap == 0:\n            return 0.0\n        elif mcap &lt; 1_000_000:  # &lt; $1M market cap\n            return 0.5  # Micro cap, lower data quality\n        elif mcap &lt; 100_000_000:  # &lt; $100M market cap  \n            return 0.8  # Small/mid cap\n        else:\n            return 1.0  # Large cap, highest data quality\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.FundamentalsPillarData.calculate_data_quality","title":"<code>calculate_data_quality(v, values)</code>","text":"<p>Calculate data quality based on market cap size.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>@validator('data_quality', always=True) \ndef calculate_data_quality(cls, v, values):\n    \"\"\"Calculate data quality based on market cap size.\"\"\"\n    mcap = values.get('market_cap_usd', 0)\n\n    if mcap == 0:\n        return 0.0\n    elif mcap &lt; 1_000_000:  # &lt; $1M market cap\n        return 0.5  # Micro cap, lower data quality\n    elif mcap &lt; 100_000_000:  # &lt; $100M market cap  \n        return 0.8  # Small/mid cap\n    else:\n        return 1.0  # Large cap, highest data quality\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.FundamentalsPillarData.calculate_volume_ratio","title":"<code>calculate_volume_ratio(v, values)</code>","text":"<p>Calculate volume to market cap ratio.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>@validator('volume_to_mcap_ratio', always=True)\ndef calculate_volume_ratio(cls, v, values):\n    \"\"\"Calculate volume to market cap ratio.\"\"\"\n    volume = values.get('volume_24h_usd', 0)\n    mcap = values.get('market_cap_usd', 1)  # Avoid division by zero\n    return round(volume / mcap, 4)\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.NansenPillarData","title":"<code>NansenPillarData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Nansen on-chain smart money flows pillar data.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>class NansenPillarData(BaseModel):\n    \"\"\"Nansen on-chain smart money flows pillar data.\"\"\"\n\n    netflow_score: float = Field(\n        ...,\n        ge=-1.0,\n        le=1.0, \n        description=\"Normalized netflow score from -1 (heavy outflow) to +1 (heavy inflow)\"\n    )\n    inflow_usd: float = Field(\n        ...,\n        ge=0.0,\n        description=\"Smart money inflow in USD\"\n    )\n    outflow_usd: float = Field(\n        ..., \n        ge=0.0,\n        description=\"Smart money outflow in USD\"\n    )\n    holder_count: Optional[int] = Field(\n        default=None,\n        ge=0,\n        description=\"Total number of token holders\"\n    )\n    data_quality: float = Field(\n        default=1.0,\n        ge=0.0,\n        le=1.0,\n        description=\"Data quality score (0=no data, 1=excellent data)\"\n    )\n\n    @validator('data_quality', always=True)\n    def calculate_data_quality(cls, v, values):\n        \"\"\"Calculate data quality based on flow volumes.\"\"\"\n        inflow = values.get('inflow_usd', 0)\n        outflow = values.get('outflow_usd', 0)\n        total_volume = inflow + outflow\n\n        if total_volume == 0:\n            return 0.0  # No smart money activity\n        elif total_volume &lt; 1000:\n            return 0.4  # Very low activity\n        elif total_volume &lt; 10000:\n            return 0.7  # Moderate activity\n        else:\n            return 1.0  # High activity\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.NansenPillarData.calculate_data_quality","title":"<code>calculate_data_quality(v, values)</code>","text":"<p>Calculate data quality based on flow volumes.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>@validator('data_quality', always=True)\ndef calculate_data_quality(cls, v, values):\n    \"\"\"Calculate data quality based on flow volumes.\"\"\"\n    inflow = values.get('inflow_usd', 0)\n    outflow = values.get('outflow_usd', 0)\n    total_volume = inflow + outflow\n\n    if total_volume == 0:\n        return 0.0  # No smart money activity\n    elif total_volume &lt; 1000:\n        return 0.4  # Very low activity\n    elif total_volume &lt; 10000:\n        return 0.7  # Moderate activity\n    else:\n        return 1.0  # High activity\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.NormalizationConfig","title":"<code>NormalizationConfig</code>  <code>dataclass</code>","text":"<p>Configuration for normalization thresholds and parameters.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>@dataclass  \nclass NormalizationConfig:\n    \"\"\"Configuration for normalization thresholds and parameters.\"\"\"\n    # Signal classification thresholds\n    bullish_threshold: float = 0.2    # Score &gt; 0.2 = Bullish\n    bearish_threshold: float = -0.2   # Score &lt; -0.2 = Bearish\n\n    # Fundamentals normalization\n    volume_sentiment_multiplier: float = 10.0  # Convert volume ratio to sentiment\n    max_volume_sentiment: float = 1.0          # Cap volume sentiment\n\n    # Data quality thresholds\n    min_twitter_tweets_good: int = 30          # Excellent quality threshold\n    min_twitter_tweets_fair: int = 10          # Good quality threshold\n    min_nansen_volume_high: float = 10000.0    # High activity threshold\n    min_nansen_volume_medium: float = 1000.0   # Moderate activity threshold\n    min_fundamentals_large_cap: float = 100_000_000  # Large cap threshold \n    min_fundamentals_mid_cap: float = 1_000_000      # Mid cap threshold\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentAnalysisResult","title":"<code>SentimentAnalysisResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete sentiment analysis result with all pillars.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>class SentimentAnalysisResult(BaseModel):\n    \"\"\"Complete sentiment analysis result with all pillars.\"\"\"\n\n    # Input data from each pillar\n    twitter_data: Optional[TwitterPillarData] = None\n    nansen_data: Optional[NansenPillarData] = None\n    fundamentals_data: Optional[FundamentalsPillarData] = None\n\n    # Computed results\n    overall_score: float = Field(\n        ...,\n        ge=-1.0,\n        le=1.0,\n        description=\"Weighted overall sentiment score from -1 to +1\"\n    )\n    confidence: float = Field(\n        ...,\n        ge=0.0,\n        le=1.0,\n        description=\"Confidence in the analysis (0-1, based on data quality)\"\n    )\n    signal: SentimentSignal = Field(\n        ...,\n        description=\"Final sentiment signal: Bullish/Neutral/Bearish\"\n    )\n\n    # Explanation\n    rationale: List[str] = Field(\n        default_factory=list,\n        description=\"Three-bullet explanation of the analysis\"\n    )\n\n    # Metadata\n    token_address: str = Field(..., description=\"Token contract address analyzed\")\n    analysis_timestamp: float = Field(..., description=\"Unix timestamp of analysis\")\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentEngine","title":"<code>SentimentEngine</code>","text":"<p>Core sentiment analysis engine that aggregates data from three pillars and computes weighted sentiment signals with confidence scores.</p> <p>Enhanced with configurable weighting and normalization logic.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>class SentimentEngine:\n    \"\"\"\n    Core sentiment analysis engine that aggregates data from three pillars\n    and computes weighted sentiment signals with confidence scores.\n\n    Enhanced with configurable weighting and normalization logic.\n    \"\"\"\n\n    def __init__(self, \n                 twitter_client: Optional[TwitterClient] = None,\n                 nansen_client: Optional[NansenClient] = None, \n                 cmc_client: Optional[CoinMarketCapClient] = None,\n                 *,\n                 weighting_config: Optional[WeightingConfig] = None,\n                 normalization_config: Optional[NormalizationConfig] = None):\n        \"\"\"Initialize with optional pre-configured API clients and configs.\"\"\"\n        self.twitter_client = twitter_client\n        self.nansen_client = nansen_client\n        self.cmc_client = cmc_client\n        self.weights = weighting_config or WeightingConfig()\n        self.norms = normalization_config or NormalizationConfig()\n\n    async def analyze_token(self, \n                          token_address: str, \n                          token_symbol: Optional[str] = None,\n                          *,\n                          chain_id: int = 1) -&gt; SentimentAnalysisResult:\n        \"\"\"\n        Perform complete sentiment analysis for a token.\n\n        Args:\n            token_address: Contract address (e.g., \"0x1234...\") \n            token_symbol: Token symbol for Twitter search (e.g., \"ETH\")\n            chain_id: Blockchain ID (1=Ethereum, 56=BSC, etc.)\n\n        Returns:\n            Complete sentiment analysis with signal and confidence\n        \"\"\"\n        import time\n\n        # Gather data from all three pillars in parallel\n        twitter_data, nansen_data, fundamentals_data = await asyncio.gather(\n            self._fetch_twitter_data(token_symbol),\n            self._fetch_nansen_data(token_address, chain_id),\n            self._fetch_fundamentals_data(token_symbol),\n            return_exceptions=True\n        )\n\n        # Handle exceptions gracefully - ensure proper types\n        twitter_result = twitter_data if not isinstance(twitter_data, Exception) else None\n        nansen_result = nansen_data if not isinstance(nansen_data, Exception) else None  \n        fundamentals_result = fundamentals_data if not isinstance(fundamentals_data, Exception) else None\n\n        # Compute weighted score and confidence\n        overall_score = self._compute_weighted_score(\n            twitter_result, nansen_result, fundamentals_result\n        )\n        confidence = self._compute_confidence(\n            twitter_result, nansen_result, fundamentals_result\n        )\n\n        # Generate rationale\n        rationale = self._generate_rationale(\n            twitter_result, nansen_result, fundamentals_result, overall_score\n        )\n\n        # Determine signal from overall score using configurable thresholds\n        if overall_score &gt; self.norms.bullish_threshold:\n            signal = SentimentSignal.BULLISH\n        elif overall_score &lt; self.norms.bearish_threshold:\n            signal = SentimentSignal.BEARISH\n        else:\n            signal = SentimentSignal.NEUTRAL\n\n        return SentimentAnalysisResult(\n            twitter_data=twitter_result,\n            nansen_data=nansen_result, \n            fundamentals_data=fundamentals_result,\n            overall_score=overall_score,\n            confidence=confidence,\n            signal=signal,\n            rationale=rationale,\n            token_address=token_address,\n            analysis_timestamp=time.time()\n        )\n\n    async def _fetch_twitter_data(self, token_symbol: Optional[str]) -&gt; Optional[TwitterPillarData]:\n        \"\"\"Fetch and process Twitter sentiment data.\"\"\"\n        if not token_symbol:\n            return None\n\n        try:\n            if self.twitter_client:\n                result = await self.twitter_client.sentiment_for_token(token_symbol)\n            else:\n                result = await get_token_sentiment(token_symbol)\n\n            return TwitterPillarData(\n                sentiment_score=result['score'],\n                tweet_count=result['tweet_count']\n            )\n        except Exception:\n            return None\n\n    async def _fetch_nansen_data(self, token_address: str, chain_id: int) -&gt; Optional[NansenPillarData]:\n        \"\"\"Fetch and process Nansen smart money data.\"\"\"\n        try:\n            if self.nansen_client:\n                flows = await self.nansen_client.smart_money_netflow(\n                    token_address, chain_id=chain_id\n                )\n                netflow_score_data = await self.nansen_client.netflow_score(\n                    token_address, chain_id=chain_id  \n                )\n                holder_count = await self.nansen_client.holder_count(\n                    token_address, chain_id=chain_id\n                )\n            else:\n                netflow_score_data = await get_nansen_netflow_score(\n                    token_address, chain_id=chain_id\n                )\n                flows = {\n                    'inflow_usd': netflow_score_data['inflow_usd'],\n                    'outflow_usd': netflow_score_data['outflow_usd']\n                }\n                holder_count = None  # Would need separate function call\n\n            return NansenPillarData(\n                netflow_score=netflow_score_data['score'],\n                inflow_usd=flows['inflow_usd'],\n                outflow_usd=flows['outflow_usd'],\n                holder_count=holder_count\n            )\n        except Exception:\n            return None\n\n    async def _fetch_fundamentals_data(self, token_symbol: Optional[str]) -&gt; Optional[FundamentalsPillarData]:\n        \"\"\"Fetch and process token fundamentals data.\"\"\"\n        if not token_symbol:\n            return None\n\n        try:\n            if self.cmc_client:\n                result = await self.cmc_client.token_quote(token_symbol)\n            else:\n                result = await get_cmc_metadata(token_symbol)\n\n            return FundamentalsPillarData(\n                market_cap_usd=result['market_cap_usd'],\n                volume_24h_usd=result['volume_24h_usd'],\n                price_usd=result['price_usd']\n            )\n        except Exception:\n            return None\n\n    def _compute_weighted_score(self, \n                              twitter_data: Optional[TwitterPillarData],\n                              nansen_data: Optional[NansenPillarData], \n                              fundamentals_data: Optional[FundamentalsPillarData]) -&gt; float:\n        \"\"\"\n        Compute weighted sentiment score from available pillar data.\n\n        Uses configurable weights and normalization parameters.\n        Handles missing data gracefully by redistributing weights.\n        \"\"\"\n        weighted_sum = 0.0\n        total_weight = 0.0\n\n        # Twitter pillar - configurable weight\n        if twitter_data and twitter_data.data_quality &gt; 0:\n            effective_weight = self.weights.twitter_weight * twitter_data.data_quality\n            weighted_sum += twitter_data.sentiment_score * effective_weight\n            total_weight += effective_weight\n\n        # Nansen pillar - configurable weight \n        if nansen_data and nansen_data.data_quality &gt; 0:\n            effective_weight = self.weights.nansen_weight * nansen_data.data_quality\n            weighted_sum += nansen_data.netflow_score * effective_weight\n            total_weight += effective_weight\n\n        # Fundamentals pillar - convert volume ratio to sentiment using config\n        if fundamentals_data and fundamentals_data.data_quality &gt; 0:\n            # Normalize volume/mcap ratio to sentiment score using configurable parameters\n            volume_sentiment = min(\n                fundamentals_data.volume_to_mcap_ratio * self.norms.volume_sentiment_multiplier,\n                self.norms.max_volume_sentiment\n            )\n            # Clamp to [-1, 1] range for consistency\n            volume_sentiment = max(-1.0, min(1.0, volume_sentiment))\n\n            effective_weight = self.weights.fundamentals_weight * fundamentals_data.data_quality\n            weighted_sum += volume_sentiment * effective_weight\n            total_weight += effective_weight\n\n        # Avoid division by zero\n        if total_weight == 0:\n            return 0.0\n\n        return weighted_sum / total_weight\n\n    def _compute_confidence(self,\n                          twitter_data: Optional[TwitterPillarData],\n                          nansen_data: Optional[NansenPillarData],\n                          fundamentals_data: Optional[FundamentalsPillarData]) -&gt; float:\n        \"\"\"\n        Compute confidence score based on data availability and quality.\n\n        Uses configurable weights to determine coverage and quality.\n        \"\"\"\n        total_possible_weight = (self.weights.twitter_weight + \n                               self.weights.nansen_weight + \n                               self.weights.fundamentals_weight)\n        actual_weight = 0.0\n        quality_weighted_sum = 0.0\n\n        # Add weight and quality for each available pillar\n        if twitter_data:\n            weight = self.weights.twitter_weight * twitter_data.data_quality\n            actual_weight += weight\n            quality_weighted_sum += weight * twitter_data.data_quality\n\n        if nansen_data:\n            weight = self.weights.nansen_weight * nansen_data.data_quality  \n            actual_weight += weight\n            quality_weighted_sum += weight * nansen_data.data_quality\n\n        if fundamentals_data:\n            weight = self.weights.fundamentals_weight * fundamentals_data.data_quality\n            actual_weight += weight  \n            quality_weighted_sum += weight * fundamentals_data.data_quality\n\n        if actual_weight == 0:\n            return 0.0\n\n        # Confidence = (actual coverage / possible coverage) * average data quality\n        coverage = actual_weight / total_possible_weight\n        avg_quality = quality_weighted_sum / actual_weight if actual_weight &gt; 0 else 0\n\n        return round(coverage * avg_quality, 3)\n\n    def _generate_rationale(self,\n                          twitter_data: Optional[TwitterPillarData],\n                          nansen_data: Optional[NansenPillarData], \n                          fundamentals_data: Optional[FundamentalsPillarData],\n                          overall_score: float) -&gt; List[str]:\n        \"\"\"\n        Generate three-bullet rationale explaining the analysis.\n\n        Provides specific, data-driven explanations for each pillar's contribution\n        to the overall sentiment with contextual metrics when available.\n        \"\"\"\n        rationale = []\n\n        # Onchain rationale (Nansen) - Most important pillar (60% weight)\n        if nansen_data and nansen_data.data_quality &gt; 0:\n            flow_total = nansen_data.inflow_usd + nansen_data.outflow_usd\n            if nansen_data.netflow_score &gt; 0.5:\n                rationale.append(f\"\u2022 Onchain: Strong smart money inflows (${flow_total:,.0f} total volume)\")\n            elif nansen_data.netflow_score &gt; 0.2:\n                rationale.append(f\"\u2022 Onchain: Moderate smart money inflows (${flow_total:,.0f} volume)\")\n            elif nansen_data.netflow_score &gt; -0.2:\n                rationale.append(f\"\u2022 Onchain: Balanced smart money flows (${flow_total:,.0f} volume)\")\n            elif nansen_data.netflow_score &gt; -0.5:\n                rationale.append(f\"\u2022 Onchain: Moderate smart money outflows (${flow_total:,.0f} volume)\")\n            else:\n                rationale.append(f\"\u2022 Onchain: Heavy smart money outflows (${flow_total:,.0f} volume)\")\n        else:\n            rationale.append(\"\u2022 Onchain: Insufficient smart money data for analysis\")\n\n        # Social rationale (Twitter) - Second pillar (25% weight)\n        if twitter_data and twitter_data.data_quality &gt; 0:\n            tweet_context = f\"({twitter_data.tweet_count} tweets analyzed)\"\n            if twitter_data.sentiment_score &gt; 0.4:\n                rationale.append(f\"\u2022 Social: Very positive community sentiment {tweet_context}\")\n            elif twitter_data.sentiment_score &gt; 0.2:\n                rationale.append(f\"\u2022 Social: Positive community sentiment {tweet_context}\")\n            elif twitter_data.sentiment_score &gt; -0.2:\n                rationale.append(f\"\u2022 Social: Neutral community sentiment {tweet_context}\")\n            elif twitter_data.sentiment_score &gt; -0.4:\n                rationale.append(f\"\u2022 Social: Negative community sentiment {tweet_context}\")\n            else:\n                rationale.append(f\"\u2022 Social: Very negative community sentiment {tweet_context}\")\n        else:\n            rationale.append(\"\u2022 Social: Limited social media activity or data\")\n\n        # Fundamentals rationale (15% weight)\n        if fundamentals_data and fundamentals_data.data_quality &gt; 0:\n            mcap_formatted = self._format_market_cap(fundamentals_data.market_cap_usd)\n            volume_ratio = fundamentals_data.volume_to_mcap_ratio\n\n            if volume_ratio &gt; 0.15:\n                activity_level = \"very high\"\n            elif volume_ratio &gt; 0.05:\n                activity_level = \"high\"\n            elif volume_ratio &gt; 0.01:\n                activity_level = \"moderate\"\n            else:\n                activity_level = \"low\"\n\n            rationale.append(f\"\u2022 Fundamentals: {activity_level} trading activity ({mcap_formatted} market cap)\")\n        else:\n            rationale.append(\"\u2022 Fundamentals: Missing or insufficient market data\")\n\n        return rationale[:3]  # Ensure exactly 3 bullets\n\n    def _format_market_cap(self, market_cap_usd: float) -&gt; str:\n        \"\"\"Format market cap for display in rationale.\"\"\"\n        if market_cap_usd &gt;= 1_000_000_000:\n            return f\"${market_cap_usd / 1_000_000_000:.1f}B\"\n        elif market_cap_usd &gt;= 1_000_000:\n            return f\"${market_cap_usd / 1_000_000:.1f}M\"\n        else:\n            return f\"${market_cap_usd / 1_000:.0f}K\"\n\n    def update_weighting_config(self, config: WeightingConfig) -&gt; None:\n        \"\"\"Update the weighting configuration.\"\"\"\n        self.weights = config\n\n    def update_normalization_config(self, config: NormalizationConfig) -&gt; None:\n        \"\"\"Update the normalization configuration.\"\"\"\n        self.norms = config\n\n    def get_current_weights(self) -&gt; Dict[str, float]:\n        \"\"\"Get current pillar weights as a dictionary.\"\"\"\n        return {\n            \"nansen\": self.weights.nansen_weight,\n            \"twitter\": self.weights.twitter_weight, \n            \"fundamentals\": self.weights.fundamentals_weight\n        } \n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentEngine.__init__","title":"<code>__init__(twitter_client=None, nansen_client=None, cmc_client=None, *, weighting_config=None, normalization_config=None)</code>","text":"<p>Initialize with optional pre-configured API clients and configs.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>def __init__(self, \n             twitter_client: Optional[TwitterClient] = None,\n             nansen_client: Optional[NansenClient] = None, \n             cmc_client: Optional[CoinMarketCapClient] = None,\n             *,\n             weighting_config: Optional[WeightingConfig] = None,\n             normalization_config: Optional[NormalizationConfig] = None):\n    \"\"\"Initialize with optional pre-configured API clients and configs.\"\"\"\n    self.twitter_client = twitter_client\n    self.nansen_client = nansen_client\n    self.cmc_client = cmc_client\n    self.weights = weighting_config or WeightingConfig()\n    self.norms = normalization_config or NormalizationConfig()\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentEngine.analyze_token","title":"<code>analyze_token(token_address, token_symbol=None, *, chain_id=1)</code>  <code>async</code>","text":"<p>Perform complete sentiment analysis for a token.</p> <p>Parameters:</p> Name Type Description Default <code>token_address</code> <code>str</code> <p>Contract address (e.g., \"0x1234...\") </p> required <code>token_symbol</code> <code>Optional[str]</code> <p>Token symbol for Twitter search (e.g., \"ETH\")</p> <code>None</code> <code>chain_id</code> <code>int</code> <p>Blockchain ID (1=Ethereum, 56=BSC, etc.)</p> <code>1</code> <p>Returns:</p> Type Description <code>SentimentAnalysisResult</code> <p>Complete sentiment analysis with signal and confidence</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>async def analyze_token(self, \n                      token_address: str, \n                      token_symbol: Optional[str] = None,\n                      *,\n                      chain_id: int = 1) -&gt; SentimentAnalysisResult:\n    \"\"\"\n    Perform complete sentiment analysis for a token.\n\n    Args:\n        token_address: Contract address (e.g., \"0x1234...\") \n        token_symbol: Token symbol for Twitter search (e.g., \"ETH\")\n        chain_id: Blockchain ID (1=Ethereum, 56=BSC, etc.)\n\n    Returns:\n        Complete sentiment analysis with signal and confidence\n    \"\"\"\n    import time\n\n    # Gather data from all three pillars in parallel\n    twitter_data, nansen_data, fundamentals_data = await asyncio.gather(\n        self._fetch_twitter_data(token_symbol),\n        self._fetch_nansen_data(token_address, chain_id),\n        self._fetch_fundamentals_data(token_symbol),\n        return_exceptions=True\n    )\n\n    # Handle exceptions gracefully - ensure proper types\n    twitter_result = twitter_data if not isinstance(twitter_data, Exception) else None\n    nansen_result = nansen_data if not isinstance(nansen_data, Exception) else None  \n    fundamentals_result = fundamentals_data if not isinstance(fundamentals_data, Exception) else None\n\n    # Compute weighted score and confidence\n    overall_score = self._compute_weighted_score(\n        twitter_result, nansen_result, fundamentals_result\n    )\n    confidence = self._compute_confidence(\n        twitter_result, nansen_result, fundamentals_result\n    )\n\n    # Generate rationale\n    rationale = self._generate_rationale(\n        twitter_result, nansen_result, fundamentals_result, overall_score\n    )\n\n    # Determine signal from overall score using configurable thresholds\n    if overall_score &gt; self.norms.bullish_threshold:\n        signal = SentimentSignal.BULLISH\n    elif overall_score &lt; self.norms.bearish_threshold:\n        signal = SentimentSignal.BEARISH\n    else:\n        signal = SentimentSignal.NEUTRAL\n\n    return SentimentAnalysisResult(\n        twitter_data=twitter_result,\n        nansen_data=nansen_result, \n        fundamentals_data=fundamentals_result,\n        overall_score=overall_score,\n        confidence=confidence,\n        signal=signal,\n        rationale=rationale,\n        token_address=token_address,\n        analysis_timestamp=time.time()\n    )\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentEngine.get_current_weights","title":"<code>get_current_weights()</code>","text":"<p>Get current pillar weights as a dictionary.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>def get_current_weights(self) -&gt; Dict[str, float]:\n    \"\"\"Get current pillar weights as a dictionary.\"\"\"\n    return {\n        \"nansen\": self.weights.nansen_weight,\n        \"twitter\": self.weights.twitter_weight, \n        \"fundamentals\": self.weights.fundamentals_weight\n    } \n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentEngine.update_normalization_config","title":"<code>update_normalization_config(config)</code>","text":"<p>Update the normalization configuration.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>def update_normalization_config(self, config: NormalizationConfig) -&gt; None:\n    \"\"\"Update the normalization configuration.\"\"\"\n    self.norms = config\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentEngine.update_weighting_config","title":"<code>update_weighting_config(config)</code>","text":"<p>Update the weighting configuration.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>def update_weighting_config(self, config: WeightingConfig) -&gt; None:\n    \"\"\"Update the weighting configuration.\"\"\"\n    self.weights = config\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.SentimentSignal","title":"<code>SentimentSignal</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Token sentiment signal classification.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>class SentimentSignal(str, Enum):\n    \"\"\"Token sentiment signal classification.\"\"\"\n    BULLISH = \"Bullish\"\n    NEUTRAL = \"Neutral\" \n    BEARISH = \"Bearish\"\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.TwitterPillarData","title":"<code>TwitterPillarData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Twitter social sentiment pillar data.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>class TwitterPillarData(BaseModel):\n    \"\"\"Twitter social sentiment pillar data.\"\"\"\n\n    sentiment_score: float = Field(\n        ..., \n        ge=-1.0, \n        le=1.0,\n        description=\"Compound sentiment score from -1 (bearish) to +1 (bullish)\"\n    )\n    tweet_count: int = Field(\n        ..., \n        ge=0,\n        description=\"Number of tweets analyzed\"\n    )\n    data_quality: float = Field(\n        default=1.0,\n        ge=0.0, \n        le=1.0,\n        description=\"Data quality score (0=no data, 1=excellent data)\"\n    )\n\n    @validator('data_quality', always=True)\n    def calculate_data_quality(cls, v, values):\n        \"\"\"Calculate data quality based on tweet count.\"\"\"\n        tweet_count = values.get('tweet_count', 0)\n        if tweet_count == 0:\n            return 0.0\n        elif tweet_count &lt; 10:\n            return 0.5  # Low data quality\n        elif tweet_count &lt; 30:\n            return 0.8  # Good data quality\n        else:\n            return 1.0  # Excellent data quality\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.TwitterPillarData.calculate_data_quality","title":"<code>calculate_data_quality(v, values)</code>","text":"<p>Calculate data quality based on tweet count.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>@validator('data_quality', always=True)\ndef calculate_data_quality(cls, v, values):\n    \"\"\"Calculate data quality based on tweet count.\"\"\"\n    tweet_count = values.get('tweet_count', 0)\n    if tweet_count == 0:\n        return 0.0\n    elif tweet_count &lt; 10:\n        return 0.5  # Low data quality\n    elif tweet_count &lt; 30:\n        return 0.8  # Good data quality\n    else:\n        return 1.0  # Excellent data quality\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.WeightingConfig","title":"<code>WeightingConfig</code>  <code>dataclass</code>","text":"<p>Configuration for pillar weighting in sentiment analysis.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>@dataclass\nclass WeightingConfig:\n    \"\"\"Configuration for pillar weighting in sentiment analysis.\"\"\"\n    nansen_weight: float = 0.60      # 60% - on-chain smart money flows\n    twitter_weight: float = 0.25     # 25% - social sentiment  \n    fundamentals_weight: float = 0.15  # 15% - token fundamentals\n\n    def __post_init__(self):\n        \"\"\"Validate weights sum to 1.0.\"\"\"\n        total = self.nansen_weight + self.twitter_weight + self.fundamentals_weight\n        if not (0.99 &lt;= total &lt;= 1.01):  # Allow small floating point errors\n            raise ValueError(f\"Weights must sum to 1.0, got {total}\")\n</code></pre>"},{"location":"api/sentiment_engine/#core.sentiment_engine.WeightingConfig.__post_init__","title":"<code>__post_init__()</code>","text":"<p>Validate weights sum to 1.0.</p> Source code in <code>core/sentiment_engine.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Validate weights sum to 1.0.\"\"\"\n    total = self.nansen_weight + self.twitter_weight + self.fundamentals_weight\n    if not (0.99 &lt;= total &lt;= 1.01):  # Allow small floating point errors\n        raise ValueError(f\"Weights must sum to 1.0, got {total}\")\n</code></pre>"},{"location":"api/validation/","title":"Validation","text":"<p>Token Address Validation Utilities</p> <p>Provides validation functions for cryptocurrency token addresses across different networks (Ethereum, Solana, etc.).</p> <p>Features: - Ethereum address validation with EIP-55 checksum support - Solana address validation with base58 decoding - Multi-chain EVM support (Ethereum, BSC, Polygon, Arbitrum, etc.) - Comprehensive format validation and normalization - Chain ID validation and network detection</p>"},{"location":"api/validation/#core.validation.AddressType","title":"<code>AddressType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Supported address types for token validation.</p> Source code in <code>core/validation.py</code> <pre><code>class AddressType(Enum):\n    \"\"\"Supported address types for token validation.\"\"\"\n    ETHEREUM = \"Ethereum\"\n    SOLANA = \"Solana\"\n    BSC = \"BNB Smart Chain\"\n    POLYGON = \"Polygon\"\n    ARBITRUM = \"Arbitrum One\"\n    OPTIMISM = \"Optimism\"\n    AVALANCHE = \"Avalanche\"\n    FANTOM = \"Fantom\"\n</code></pre>"},{"location":"api/validation/#core.validation.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for address validation errors.</p> Source code in <code>core/validation.py</code> <pre><code>class ValidationError(Exception):\n    \"\"\"Custom exception for address validation errors.\"\"\"\n    pass\n</code></pre>"},{"location":"api/validation/#core.validation.ValidationResult","title":"<code>ValidationResult</code>","text":"<p>Enhanced validation result with detailed information.</p> Source code in <code>core/validation.py</code> <pre><code>class ValidationResult:\n    \"\"\"Enhanced validation result with detailed information.\"\"\"\n\n    def __init__(self, address: str, address_type: AddressType, is_valid: bool, \n                 normalized_address: Optional[str] = None, warnings: Optional[List[str]] = None):\n        self.address = address\n        self.address_type = address_type\n        self.is_valid = is_valid\n        self.normalized_address = normalized_address or address\n        self.warnings = warnings or []\n\n    def __bool__(self):\n        return self.is_valid\n</code></pre>"},{"location":"api/validation/#core.validation.batch_validate_addresses","title":"<code>batch_validate_addresses(addresses, strict_checksum=False)</code>","text":"<p>Validate multiple addresses at once.</p> <p>Parameters:</p> Name Type Description Default <code>addresses</code> <code>List[str]</code> <p>List of addresses to validate</p> required <code>strict_checksum</code> <code>bool</code> <p>Whether to enforce strict checksum validation</p> <code>False</code> <p>Returns:</p> Type Description <code>List[dict]</code> <p>List[dict]: List of validation results</p> Source code in <code>core/validation.py</code> <pre><code>def batch_validate_addresses(addresses: List[str], strict_checksum: bool = False) -&gt; List[dict]:\n    \"\"\"\n    Validate multiple addresses at once.\n\n    Args:\n        addresses: List of addresses to validate\n        strict_checksum: Whether to enforce strict checksum validation\n\n    Returns:\n        List[dict]: List of validation results\n    \"\"\"\n    results = []\n    for address in addresses:\n        try:\n            info = get_address_info(address)\n            if strict_checksum:\n                # Re-validate with strict checksum\n                detailed_result = validate_token_address_detailed(address, strict_checksum=True)\n                if detailed_result and detailed_result.warnings:\n                    info['is_valid'] = False\n                    info['warnings'] = detailed_result.warnings\n            results.append(info)\n        except Exception as e:\n            results.append({\n                'address': address,\n                'is_valid': False,\n                'error': str(e)\n            })\n\n    return results \n</code></pre>"},{"location":"api/validation/#core.validation.detect_address_format","title":"<code>detect_address_format(address)</code>","text":"<p>Detect the likely format of an address without full validation.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The address to analyze</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>Optional[str]</code> <p>Detected format ('ethereum', 'solana', 'unknown')</p> Source code in <code>core/validation.py</code> <pre><code>def detect_address_format(address: str) -&gt; Optional[str]:\n    \"\"\"\n    Detect the likely format of an address without full validation.\n\n    Args:\n        address: The address to analyze\n\n    Returns:\n        str: Detected format ('ethereum', 'solana', 'unknown')\n    \"\"\"\n    if not address:\n        return None\n\n    cleaned = address.strip()\n\n    # Check for Ethereum-like format\n    if cleaned.startswith('0x') and len(cleaned) == 42:\n        return 'ethereum'\n\n    # Check for Solana-like format\n    if (32 &lt;= len(cleaned) &lt;= 44 and \n        all(c in \"123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\" for c in cleaned)):\n        return 'solana'\n\n    return 'unknown'\n</code></pre>"},{"location":"api/validation/#core.validation.get_address_info","title":"<code>get_address_info(address)</code>","text":"<p>Get comprehensive information about an address.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The address to analyze</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Address information including format, validity, warnings, etc.</p> Source code in <code>core/validation.py</code> <pre><code>def get_address_info(address: str) -&gt; dict:\n    \"\"\"\n    Get comprehensive information about an address.\n\n    Args:\n        address: The address to analyze\n\n    Returns:\n        dict: Address information including format, validity, warnings, etc.\n    \"\"\"\n    if not address:\n        return {\n            'address': address,\n            'is_valid': False,\n            'format': 'unknown',\n            'error': 'Empty address'\n        }\n\n    # Detect format\n    detected_format = detect_address_format(address)\n\n    # Get detailed validation\n    validation_result = validate_token_address_detailed(address)\n\n    info = {\n        'address': address,\n        'detected_format': detected_format,\n        'is_valid': validation_result.is_valid if validation_result else False,\n        'warnings': validation_result.warnings if validation_result else [],\n    }\n\n    if validation_result and validation_result.is_valid:\n        info.update({\n            'address_type': validation_result.address_type.value,\n            'normalized_address': validation_result.normalized_address,\n            'supported_chains': _get_supported_chains(validation_result.address_type)\n        })\n    else:\n        info['error'] = 'Invalid address format'\n\n    return info\n</code></pre>"},{"location":"api/validation/#core.validation.get_network_name","title":"<code>get_network_name(chain_id)</code>","text":"<p>Get human-readable network name from chain ID.</p> <p>Parameters:</p> Name Type Description Default <code>chain_id</code> <code>int</code> <p>The blockchain chain ID</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Human-readable network name</p> Source code in <code>core/validation.py</code> <pre><code>def get_network_name(chain_id: int) -&gt; str:\n    \"\"\"\n    Get human-readable network name from chain ID.\n\n    Args:\n        chain_id: The blockchain chain ID\n\n    Returns:\n        str: Human-readable network name\n    \"\"\"\n    CHAIN_ID_NAMES = {\n        1: \"Ethereum\",\n        56: \"BNB Smart Chain\",\n        137: \"Polygon\",\n        42161: \"Arbitrum One\",\n        10: \"Optimism\",\n        43114: \"Avalanche\",\n        250: \"Fantom\",\n        25: \"Cronos\",\n    }\n\n    return CHAIN_ID_NAMES.get(chain_id, f\"Chain {chain_id}\")\n</code></pre>"},{"location":"api/validation/#core.validation.is_contract_address_format","title":"<code>is_contract_address_format(address)</code>","text":"<p>Check if address format is suitable for smart contracts.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The address to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if format supports smart contracts</p> Source code in <code>core/validation.py</code> <pre><code>def is_contract_address_format(address: str) -&gt; bool:\n    \"\"\"\n    Check if address format is suitable for smart contracts.\n\n    Args:\n        address: The address to check\n\n    Returns:\n        bool: True if format supports smart contracts\n    \"\"\"\n    validation_result = validate_token_address_detailed(address)\n    if not validation_result or not validation_result.is_valid:\n        return False\n\n    # EVM chains support smart contracts\n    if validation_result.address_type in [AddressType.ETHEREUM, AddressType.BSC, \n                                        AddressType.POLYGON, AddressType.ARBITRUM, \n                                        AddressType.OPTIMISM, AddressType.AVALANCHE, \n                                        AddressType.FANTOM]:\n        return True\n\n    # Solana uses program addresses (also valid for tokens)\n    if validation_result.address_type == AddressType.SOLANA:\n        return True\n\n    return False\n</code></pre>"},{"location":"api/validation/#core.validation.is_valid_chain_id","title":"<code>is_valid_chain_id(chain_id)</code>","text":"<p>Check if chain ID is supported.</p> <p>Parameters:</p> Name Type Description Default <code>chain_id</code> <code>int</code> <p>The blockchain chain ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if chain ID is supported</p> Source code in <code>core/validation.py</code> <pre><code>def is_valid_chain_id(chain_id: int) -&gt; bool:\n    \"\"\"\n    Check if chain ID is supported.\n\n    Args:\n        chain_id: The blockchain chain ID\n\n    Returns:\n        bool: True if chain ID is supported\n    \"\"\"\n    # Common chain IDs\n    SUPPORTED_CHAIN_IDS = {\n        1,      # Ethereum Mainnet\n        56,     # BSC Mainnet\n        137,    # Polygon Mainnet\n        42161,  # Arbitrum One\n        10,     # Optimism\n        43114,  # Avalanche C-Chain\n        250,    # Fantom Opera\n        25,     # Cronos Mainnet\n    }\n\n    return chain_id in SUPPORTED_CHAIN_IDS\n</code></pre>"},{"location":"api/validation/#core.validation.normalize_address","title":"<code>normalize_address(address, address_type)</code>","text":"<p>Normalize address format based on type.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The address to normalize</p> required <code>address_type</code> <code>AddressType</code> <p>The type of address</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Normalized address</p> Source code in <code>core/validation.py</code> <pre><code>def normalize_address(address: str, address_type: AddressType) -&gt; str:\n    \"\"\"\n    Normalize address format based on type.\n\n    Args:\n        address: The address to normalize\n        address_type: The type of address\n\n    Returns:\n        str: Normalized address\n    \"\"\"\n    if address_type in [AddressType.ETHEREUM, AddressType.BSC, AddressType.POLYGON, \n                       AddressType.ARBITRUM, AddressType.OPTIMISM, AddressType.AVALANCHE, \n                       AddressType.FANTOM]:\n        # EVM addresses should be lowercase (EIP-55 checksumming optional)\n        return address.lower()\n    elif address_type == AddressType.SOLANA:\n        # Solana addresses are case-sensitive\n        return address\n    else:\n        return address\n</code></pre>"},{"location":"api/validation/#core.validation.validate_ethereum_address","title":"<code>validate_ethereum_address(address, check_checksum=True)</code>","text":"<p>Validate Ethereum address format with optional EIP-55 checksum validation.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The address string to validate</p> required <code>check_checksum</code> <code>bool</code> <p>Whether to validate EIP-55 checksum</p> <code>True</code> <p>Returns:</p> Name Type Description <code>ValidationResult</code> <code>ValidationResult</code> <p>Detailed validation result</p> Source code in <code>core/validation.py</code> <pre><code>def validate_ethereum_address(address: str, check_checksum: bool = True) -&gt; ValidationResult:\n    \"\"\"\n    Validate Ethereum address format with optional EIP-55 checksum validation.\n\n    Args:\n        address: The address string to validate\n        check_checksum: Whether to validate EIP-55 checksum\n\n    Returns:\n        ValidationResult: Detailed validation result\n    \"\"\"\n    if not address:\n        return ValidationResult(address, AddressType.ETHEREUM, False)\n\n    # Remove any whitespace\n    cleaned_address = address.strip()\n\n    # Check basic format: 0x followed by 40 hexadecimal characters\n    ethereum_pattern = r'^0x[a-fA-F0-9]{40}$'\n\n    if not re.match(ethereum_pattern, cleaned_address):\n        return ValidationResult(address, AddressType.ETHEREUM, False)\n\n    # Normalize to lowercase\n    normalized = cleaned_address.lower()\n    warnings = []\n\n    # Check EIP-55 checksum if requested and address has mixed case\n    # Only check if the hex part (after 0x) has mixed case\n    hex_part = cleaned_address[2:]\n    if check_checksum and hex_part != hex_part.lower() and hex_part != hex_part.upper():\n        if not _is_valid_eip55_checksum(cleaned_address):\n            warnings.append(\"Invalid EIP-55 checksum - address may be incorrectly formatted\")\n\n    return ValidationResult(\n        address=cleaned_address,\n        address_type=AddressType.ETHEREUM,\n        is_valid=True,\n        normalized_address=normalized,\n        warnings=warnings\n    )\n</code></pre>"},{"location":"api/validation/#core.validation.validate_solana_address","title":"<code>validate_solana_address(address)</code>","text":"<p>Validate Solana address format (base58) with proper decoding.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The address string to validate</p> required <p>Returns:</p> Name Type Description <code>ValidationResult</code> <code>ValidationResult</code> <p>Detailed validation result</p> Source code in <code>core/validation.py</code> <pre><code>def validate_solana_address(address: str) -&gt; ValidationResult:\n    \"\"\"\n    Validate Solana address format (base58) with proper decoding.\n\n    Args:\n        address: The address string to validate\n\n    Returns:\n        ValidationResult: Detailed validation result\n    \"\"\"\n    if not address:\n        return ValidationResult(address, AddressType.SOLANA, False)\n\n    # Remove any whitespace\n    cleaned_address = address.strip()\n\n    # Solana addresses are base58 encoded, typically 32-44 characters\n    # Base58 alphabet: 123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz\n    # (excludes 0, O, I, l to avoid confusion)\n    solana_pattern = r'^[1-9A-HJ-NP-Za-km-z]{32,44}$'\n\n    if not re.match(solana_pattern, cleaned_address):\n        return ValidationResult(address, AddressType.SOLANA, False)\n\n    # Validate base58 decoding\n    try:\n        decoded = _base58_decode(cleaned_address)\n        if len(decoded) != 32:  # Solana addresses should decode to 32 bytes\n            return ValidationResult(\n                address=cleaned_address,\n                address_type=AddressType.SOLANA,\n                is_valid=False\n            )\n    except (ValueError, Exception):\n        return ValidationResult(address, AddressType.SOLANA, False)\n\n    return ValidationResult(\n        address=cleaned_address,\n        address_type=AddressType.SOLANA,\n        is_valid=True,\n        normalized_address=cleaned_address  # Solana addresses are case-sensitive\n    )\n</code></pre>"},{"location":"api/validation/#core.validation.validate_token_address","title":"<code>validate_token_address(address, strict_checksum=False)</code>","text":"<p>Validate a token address and determine its type.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The token address to validate</p> required <code>strict_checksum</code> <code>bool</code> <p>Whether to enforce strict EIP-55 checksum validation</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[Tuple[str, AddressType]]</code> <p>Tuple of (cleaned_address, address_type) if valid, None if invalid</p> Source code in <code>core/validation.py</code> <pre><code>def validate_token_address(address: str, strict_checksum: bool = False) -&gt; Optional[Tuple[str, AddressType]]:\n    \"\"\"\n    Validate a token address and determine its type.\n\n    Args:\n        address: The token address to validate\n        strict_checksum: Whether to enforce strict EIP-55 checksum validation\n\n    Returns:\n        Tuple of (cleaned_address, address_type) if valid, None if invalid\n    \"\"\"\n    if not address:\n        return None\n\n    # Clean the address\n    cleaned_address = address.strip()\n\n    # Check Ethereum/EVM format first\n    eth_result = validate_ethereum_address(cleaned_address, check_checksum=strict_checksum)\n    if eth_result.is_valid:\n        # For strict mode, reject if there are checksum warnings\n        if strict_checksum and eth_result.warnings:\n            return None\n        return (eth_result.normalized_address, AddressType.ETHEREUM)\n\n    # Check Solana format\n    sol_result = validate_solana_address(cleaned_address)\n    if sol_result.is_valid:\n        return (sol_result.normalized_address, AddressType.SOLANA)\n\n    # Not a recognized format\n    return None\n</code></pre>"},{"location":"api/validation/#core.validation.validate_token_address_detailed","title":"<code>validate_token_address_detailed(address, strict_checksum=False)</code>","text":"<p>Validate a token address with detailed validation information.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>str</code> <p>The token address to validate</p> required <code>strict_checksum</code> <code>bool</code> <p>Whether to enforce strict EIP-55 checksum validation</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[ValidationResult]</code> <p>ValidationResult if valid, None if invalid</p> Source code in <code>core/validation.py</code> <pre><code>def validate_token_address_detailed(address: str, strict_checksum: bool = False) -&gt; Optional[ValidationResult]:\n    \"\"\"\n    Validate a token address with detailed validation information.\n\n    Args:\n        address: The token address to validate\n        strict_checksum: Whether to enforce strict EIP-55 checksum validation\n\n    Returns:\n        ValidationResult if valid, None if invalid\n    \"\"\"\n    if not address:\n        return None\n\n    # Clean the address\n    cleaned_address = address.strip()\n\n    # Check Ethereum/EVM format first\n    eth_result = validate_ethereum_address(cleaned_address, check_checksum=strict_checksum)\n    if eth_result.is_valid:\n        # For strict mode, reject if there are checksum warnings\n        if strict_checksum and eth_result.warnings:\n            eth_result.is_valid = False\n            return eth_result\n        return eth_result\n\n    # Check Solana format\n    sol_result = validate_solana_address(cleaned_address)\n    if sol_result.is_valid:\n        return sol_result\n\n    # Return the first failed result for error details\n    return eth_result if cleaned_address.startswith('0x') else sol_result\n</code></pre>"},{"location":"development/deployment/","title":"Deployment","text":""},{"location":"development/deployment/#overview","title":"Overview","text":"<p>The Token Sentiment Bot is designed for easy deployment with multiple options ranging from free MVP hosting to production-ready infrastructure.</p>"},{"location":"development/deployment/#deployment-options","title":"Deployment Options","text":""},{"location":"development/deployment/#free-mvp-options","title":"\ud83c\udd93 Free MVP Options","text":""},{"location":"development/deployment/#1-local-development","title":"1. Local Development","text":"<p><pre><code># Run bot in polling mode (no webhook needed)\npython -m bot.main\n</code></pre> Cost: $0/month Pros: No setup, immediate testing Cons: Requires your computer to be running</p>"},{"location":"development/deployment/#2-railwayapp-free-tier","title":"2. Railway.app (Free Tier)","text":"<p><pre><code># Deploy to Railway (free tier: 500 hours/month)\nrailway login\nrailway init\nrailway up\n</code></pre> Cost: $0/month (500 hours free) Pros: Easy deployment, automatic HTTPS Cons: Limited hours, may sleep after inactivity</p>"},{"location":"development/deployment/#3-rendercom-free-tier","title":"3. Render.com (Free Tier)","text":"<p><pre><code># Deploy to Render (free tier: 750 hours/month)\n# Connect GitHub repo and deploy automatically\n</code></pre> Cost: $0/month (750 hours free) Pros: Easy setup, good documentation Cons: Sleeps after 15 minutes of inactivity</p>"},{"location":"development/deployment/#paid-production-options","title":"\ud83d\udcb0 Paid Production Options","text":""},{"location":"development/deployment/#1-railwayapp-paid","title":"1. Railway.app (Paid)","text":"<ul> <li>Starter: $5/month (unlimited hours)</li> <li>Pro: $20/month (better performance)</li> </ul>"},{"location":"development/deployment/#2-rendercom-paid","title":"2. Render.com (Paid)","text":"<ul> <li>Starter: $7/month (always on)</li> <li>Standard: $25/month (better performance)</li> </ul>"},{"location":"development/deployment/#3-digitalocean-app-platform","title":"3. DigitalOcean App Platform","text":"<ul> <li>Basic: $5/month (512MB RAM)</li> <li>Professional: $12/month (1GB RAM)</li> </ul>"},{"location":"development/deployment/#environment-configuration","title":"Environment Configuration","text":""},{"location":"development/deployment/#required-environment-variables","title":"Required Environment Variables","text":"<pre><code># Telegram Bot\nTELEGRAM_BOT_TOKEN=your_bot_token_here\n\n# Data Sources\nNANSEN_API_KEY=your_nansen_api_key\nTWITTER_BEARER_TOKEN=your_twitter_bearer_token\nCOINGECKO_API_KEY=your_coingecko_api_key\n\n# Optional: Redis (for production scaling)\nREDIS_URL=redis://localhost:6379\nUSE_REDIS=true  # Set to false for in-memory only\n</code></pre>"},{"location":"development/deployment/#optional-configuration","title":"Optional Configuration","text":"<pre><code># Webhook settings (for production)\nWEBHOOK_URL=https://your-domain.com\nWEBHOOK_PORT=8443\n\n# Bot settings\nRATE_LIMIT_WINDOW=60\nRATE_LIMIT_MAX_REQUESTS=2\n</code></pre>"},{"location":"development/deployment/#deployment-steps","title":"Deployment Steps","text":""},{"location":"development/deployment/#1-prepare-your-bot","title":"1. Prepare Your Bot","text":"<pre><code># Clone repository\ngit clone https://github.com/yourusername/token-sentiment-bot.git\ncd token-sentiment-bot\n\n# Install dependencies\npip install -r requirements.txt\n\n# Test locally\npython -m pytest tests/ -v\n</code></pre>"},{"location":"development/deployment/#2-set-up-environment-variables","title":"2. Set Up Environment Variables","text":"<p>Create a <code>.env</code> file or set environment variables in your hosting platform: <pre><code>cp .env.example .env\n# Edit .env with your API keys\n</code></pre></p>"},{"location":"development/deployment/#3-deploy-to-your-chosen-platform","title":"3. Deploy to Your Chosen Platform","text":""},{"location":"development/deployment/#railwayapp","title":"Railway.app","text":"<pre><code># Install Railway CLI\nnpm install -g @railway/cli\n\n# Login and deploy\nrailway login\nrailway init\nrailway up\n</code></pre>"},{"location":"development/deployment/#rendercom","title":"Render.com","text":"<ol> <li>Connect your GitHub repository</li> <li>Create a new Web Service</li> <li>Set build command: <code>pip install -r requirements.txt</code></li> <li>Set start command: <code>python -m bot.main</code></li> <li>Add environment variables</li> </ol>"},{"location":"development/deployment/#digitalocean-app-platform","title":"DigitalOcean App Platform","text":"<ol> <li>Create a new App</li> <li>Connect your GitHub repository</li> <li>Configure as Python app</li> <li>Set environment variables</li> <li>Deploy</li> </ol>"},{"location":"development/deployment/#4-configure-webhook-production","title":"4. Configure Webhook (Production)","text":"<pre><code># Set webhook URL in your bot\nWEBHOOK_URL = \"https://your-domain.com\"\n</code></pre>"},{"location":"development/deployment/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":""},{"location":"development/deployment/#health-checks","title":"Health Checks","text":"<ul> <li>Uptime Monitoring: Use UptimeRobot (free)</li> <li>Error Tracking: Use Sentry (free tier available)</li> <li>Performance Monitoring: Built-in <code>/stats</code> command</li> </ul>"},{"location":"development/deployment/#logs-and-debugging","title":"Logs and Debugging","text":"<pre><code># View logs\nrailway logs  # Railway\nrender logs   # Render\ndoctl apps logs  # DigitalOcean\n</code></pre>"},{"location":"development/deployment/#scaling-considerations","title":"Scaling Considerations","text":"<ul> <li>Memory: 512MB minimum, 1GB recommended</li> <li>CPU: 0.5 vCPU minimum, 1 vCPU recommended</li> <li>Storage: 1GB minimum for logs and cache</li> </ul>"},{"location":"development/deployment/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>API Key Management: Use environment variables, never commit to code</li> <li>HTTPS: Always use HTTPS in production</li> <li>Rate Limiting: Configure appropriate rate limits</li> <li>Input Validation: All user inputs are validated</li> <li>Error Handling: No sensitive data in error messages</li> </ol>"},{"location":"development/deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/deployment/#common-issues","title":"Common Issues","text":"<ol> <li>Bot Not Responding: Check TELEGRAM_BOT_TOKEN</li> <li>API Errors: Verify API keys and quotas</li> <li>Memory Issues: Increase memory allocation</li> <li>Timeout Errors: Check network connectivity</li> </ol>"},{"location":"development/deployment/#debug-mode","title":"Debug Mode","text":"<pre><code># Run with debug logging\npython -m bot.main --debug\n</code></pre>"},{"location":"development/deployment/#performance-optimization","title":"Performance Optimization","text":""},{"location":"development/deployment/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>MVP: In-memory caching (no additional cost)</li> <li>Production: Redis caching for better performance</li> </ul>"},{"location":"development/deployment/#rate-limiting","title":"Rate Limiting","text":"<ul> <li>Default: 2 analyses per minute per user</li> <li>Configurable: Adjust based on your needs</li> </ul>"},{"location":"development/deployment/#response-time","title":"Response Time","text":"<ul> <li>Target: &lt;7 seconds median</li> <li>Optimization: Parallel API calls, caching </li> </ul>"},{"location":"development/load_testing/","title":"Load Testing","text":""},{"location":"development/load_testing/#overview","title":"Overview","text":"<p>The Token Sentiment Bot uses Locust for load testing, simulating multiple concurrent users to validate performance under load.</p>"},{"location":"development/load_testing/#configuration","title":"Configuration","text":"<p>The load testing is configured in <code>locustfile.py</code> and simulates: - Realistic Telegram update payloads - Random user IDs and message content - Configurable user count and spawn rate - Realistic wait times between requests</p>"},{"location":"development/load_testing/#running-load-tests","title":"Running Load Tests","text":""},{"location":"development/load_testing/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install Locust: <code>pip install locust</code></li> <li>Ensure your bot is running and accessible</li> <li>Verify the webhook endpoint is <code>/webhook</code></li> </ol>"},{"location":"development/load_testing/#basic-load-test","title":"Basic Load Test","text":"<pre><code># Simulate 50 concurrent users, spawning 10 per second\nlocust -f locustfile.py --headless -u 50 -r 10 -H http://localhost:8000\n</code></pre>"},{"location":"development/load_testing/#interactive-mode","title":"Interactive Mode","text":"<p><pre><code># Start Locust web interface\nlocust -f locustfile.py -H http://localhost:8000\n</code></pre> Then open http://localhost:8089 in your browser.</p>"},{"location":"development/load_testing/#custom-parameters","title":"Custom Parameters","text":"<pre><code># Different user count and spawn rate\nlocust -f locustfile.py --headless -u 100 -r 20 -H http://localhost:8000\n\n# Longer test duration\nlocust -f locustfile.py --headless -u 50 -r 10 -H http://localhost:8000 --run-time 5m\n</code></pre>"},{"location":"development/load_testing/#test-scenarios","title":"Test Scenarios","text":""},{"location":"development/load_testing/#telegrambotuser-class","title":"TelegramBotUser Class","text":"<p>The main test class that simulates Telegram users:</p> <pre><code>class TelegramBotUser(HttpUser):\n    wait_time = between(1, 3)  # Realistic user think time\n\n    @task\n    def send_message(self):\n        # Send simulated Telegram update to webhook\n        payload = {...}\n        self.client.post(WEBHOOK_PATH, json=payload)\n</code></pre>"},{"location":"development/load_testing/#payload-structure","title":"Payload Structure","text":"<p>Each request sends a realistic Telegram update: <pre><code>{\n  \"update_id\": 123456,\n  \"message\": {\n    \"message_id\": 789,\n    \"from\": {\"id\": 12345, \"is_bot\": false, \"first_name\": \"TestUser\"},\n    \"chat\": {\"id\": 12345, \"type\": \"private\"},\n    \"date\": 1680000000,\n    \"text\": \"random_message\"\n  }\n}\n</code></pre></p>"},{"location":"development/load_testing/#performance-targets","title":"Performance Targets","text":"<ul> <li>Response Time: &lt;7 seconds median</li> <li>Concurrent Users: 50+ without degradation</li> <li>Error Rate: &lt;1% under normal load</li> <li>Throughput: 10+ requests per second</li> </ul>"},{"location":"development/load_testing/#interpreting-results","title":"Interpreting Results","text":""},{"location":"development/load_testing/#key-metrics","title":"Key Metrics","text":"<ul> <li>RPS: Requests per second</li> <li>Response Time: Average, median, 95th percentile</li> <li>Error Rate: Percentage of failed requests</li> <li>User Count: Number of concurrent users</li> </ul>"},{"location":"development/load_testing/#example-output","title":"Example Output","text":"<pre><code>Type     Name              # reqs      # fails |    Avg     Min     Max    Median |   req/s  failures/s\n--------|----------------|-----------|---------|---------|-------|-------|--------|---------|---------\nPOST     /webhook             1000         0(0.00%) |    245    120    890      220 |    10.00     0.00\n--------|----------------|-----------|---------|---------|-------|-------|--------|---------|---------\n         Aggregated           1000         0(0.00%) |    245    120    890      220 |    10.00     0.00\n</code></pre>"},{"location":"development/load_testing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/load_testing/#common-issues","title":"Common Issues","text":"<ol> <li>Connection Refused: Ensure bot is running and accessible</li> <li>404 Errors: Verify webhook path is correct</li> <li>High Error Rate: Check bot logs for issues</li> <li>Slow Response: Monitor bot performance and resources</li> </ol>"},{"location":"development/load_testing/#debug-mode","title":"Debug Mode","text":"<pre><code># Run with verbose output\nlocust -f locustfile.py --headless -u 5 -r 1 -H http://localhost:8000 --loglevel DEBUG\n</code></pre>"},{"location":"development/load_testing/#integration-with-cicd","title":"Integration with CI/CD","text":"<p>Load tests can be integrated into CI/CD pipelines: <pre><code>- name: Run Load Tests\n  run: |\n    # Start bot in background\n    python -m bot.main &amp;\n    sleep 10\n\n    # Run load test\n    locust -f locustfile.py --headless -u 10 -r 2 -H http://localhost:8000 --run-time 1m\n</code></pre></p>"},{"location":"development/testing/","title":"Testing","text":""},{"location":"development/testing/#overview","title":"Overview","text":"<p>The Token Sentiment Bot includes a comprehensive test suite with 150+ tests achieving 77% code coverage.</p>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_sentiment_engine.py    # Core sentiment analysis tests\n\u251c\u2500\u2500 test_data_sources.py        # API integration tests\n\u251c\u2500\u2500 test_validation.py          # Address validation tests\n\u251c\u2500\u2500 test_bot_integration.py     # Bot functionality tests\n\u251c\u2500\u2500 test_cache.py               # Caching system tests\n\u251c\u2500\u2500 test_http_utils.py          # HTTP utilities tests\n\u2514\u2500\u2500 test_rate_limit.py          # Rate limiting tests\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#all-tests","title":"All Tests","text":"<pre><code>python -m pytest tests/ -v\n</code></pre>"},{"location":"development/testing/#with-coverage","title":"With Coverage","text":"<pre><code>python -m pytest --cov=core --cov=bot --cov-report=term-missing\n</code></pre>"},{"location":"development/testing/#specific-test-categories","title":"Specific Test Categories","text":"<pre><code># Sentiment engine tests\npython -m pytest tests/test_sentiment_engine.py -v\n\n# Integration tests\npython -m pytest tests/test_data_sources.py -v\n\n# Bot tests\npython -m pytest tests/test_bot_integration.py -v\n</code></pre>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":""},{"location":"development/testing/#unit-tests","title":"Unit Tests","text":"<ul> <li>Data Models: Pydantic model validation and calculations</li> <li>Business Logic: Sentiment scoring, confidence calculation</li> <li>Utilities: Address validation, HTTP retries, caching</li> </ul>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":"<ul> <li>API Wrappers: Mocked external API calls (Twitter, Nansen, CoinGecko)</li> <li>Cache Integration: Redis and in-memory cache behavior</li> <li>Bot Commands: Telegram bot command handling</li> </ul>"},{"location":"development/testing/#edge-cases","title":"Edge Cases","text":"<ul> <li>No Data Scenarios: Missing pillar data handling</li> <li>Error Conditions: API failures, network timeouts</li> <li>Boundary Values: Extreme sentiment scores, market caps</li> </ul>"},{"location":"development/testing/#coverage-report","title":"Coverage Report","text":"<p>Current coverage breakdown: - <code>core/sentiment_engine.py</code>: 82% - <code>core/data_sources.py</code>: 86% - <code>core/cache.py</code>: 93% - <code>core/http_utils.py</code>: 95% - <code>core/rate_limiter.py</code>: 98% - <code>core/validation.py</code>: 88% - <code>bot/main.py</code>: 39%</p>"},{"location":"development/testing/#cicd-integration","title":"CI/CD Integration","text":"<p>Tests run automatically on: - Push to main branch - Pull requests - Coverage reporting to Codecov</p>"},{"location":"development/testing/#best-practices","title":"Best Practices","text":"<ol> <li>Test Naming: Descriptive test names that explain the scenario</li> <li>Mocking: Use mocks for external dependencies</li> <li>Edge Cases: Test boundary conditions and error scenarios</li> <li>Async Testing: Proper async/await patterns for async functions</li> <li>Isolation: Each test should be independent and not affect others </li> </ol>"}]}